{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> **HW4 Dataset 3**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"MLmetrics\")\n",
    "#install.packages(\"gbm\")\n",
    "library(caret)\n",
    "library(glmnet)\n",
    "library(CVXR)\n",
    "library(MLmetrics)\n",
    "library(data.table)\n",
    "library(glmnet)\n",
    "library(gbm)\n",
    "library(tidyverse)\n",
    "library(readxl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> **Dataset 3: Cardiotocography Data Set**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set Information:\n",
    "\n",
    "2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "LB - FHR baseline (beats per minute)\n",
    "AC - # of accelerations per second\n",
    "FM - # of fetal movements per second\n",
    "UC - # of uterine contractions per second\n",
    "DL - # of light decelerations per second\n",
    "DS - # of severe decelerations per second\n",
    "DP - # of prolongued decelerations per second\n",
    "ASTV - percentage of time with abnormal short term variability\n",
    "MSTV - mean value of short term variability\n",
    "ALTV - percentage of time with abnormal long term variability\n",
    "MLTV - mean value of long term variability\n",
    "Width - width of FHR histogram\n",
    "Min - minimum of FHR histogram\n",
    "Max - Maximum of FHR histogram\n",
    "Nmax - # of histogram peaks\n",
    "Nzeros - # of histogram zeros\n",
    "Mode - histogram mode\n",
    "Mean - histogram mean\n",
    "Median - histogram median\n",
    "Variance - histogram variance\n",
    "Tendency - histogram tendency\n",
    "CLASS - FHR pattern class code (1 to 10)\n",
    "NSP - fetal state class code (N=normal; S=suspect; P=pathologic)\n",
    "\n",
    "\n",
    "Relevant Papers:\n",
    "\n",
    "Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'>I focused only NSP column. Therefore I excluded CLASS column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitControl = trainControl(method = \"cv\", number = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_grid = expand.grid(alpha = 1, lambda = c(0,0.5,1))\n",
    "dt_grid = expand.grid(cp = c(0.01,0.05,0.1))\n",
    "rf_grid = expand.grid( mtry = c(3,5,7))\n",
    "sgb_grid = expand.grid(n.trees = c(30, 50,100), shrinkage = c(0.05,0.1), interaction.depth = c(10, 20), n.minobsinnode = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>LB</th><th scope=col>AC</th><th scope=col>FM</th><th scope=col>UC</th><th scope=col>DL</th><th scope=col>DS</th><th scope=col>DP</th><th scope=col>ASTV</th><th scope=col>MSTV</th><th scope=col>ALTV</th><th scope=col>...</th><th scope=col>Min</th><th scope=col>Max</th><th scope=col>Nmax</th><th scope=col>Nzeros</th><th scope=col>Mode</th><th scope=col>Mean</th><th scope=col>Median</th><th scope=col>Variance</th><th scope=col>Tendency</th><th scope=col>NSP</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>120  </td><td>0.000</td><td>0.000</td><td>0.000</td><td>0.000</td><td>0    </td><td>0.000</td><td>73   </td><td>0.5  </td><td>43   </td><td>...  </td><td> 62  </td><td>126  </td><td> 2   </td><td>0    </td><td>120  </td><td>137  </td><td>121  </td><td> 73  </td><td> 1   </td><td>2    </td></tr>\n",
       "\t<tr><td>132  </td><td>0.006</td><td>0.000</td><td>0.006</td><td>0.003</td><td>0    </td><td>0.000</td><td>17   </td><td>2.1  </td><td> 0   </td><td>...  </td><td> 68  </td><td>198  </td><td> 6   </td><td>1    </td><td>141  </td><td>136  </td><td>140  </td><td> 12  </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>133  </td><td>0.003</td><td>0.000</td><td>0.008</td><td>0.003</td><td>0    </td><td>0.000</td><td>16   </td><td>2.1  </td><td> 0   </td><td>...  </td><td> 68  </td><td>198  </td><td> 5   </td><td>1    </td><td>141  </td><td>135  </td><td>138  </td><td> 13  </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>134  </td><td>0.003</td><td>0.000</td><td>0.008</td><td>0.003</td><td>0    </td><td>0.000</td><td>16   </td><td>2.4  </td><td> 0   </td><td>...  </td><td> 53  </td><td>170  </td><td>11   </td><td>0    </td><td>137  </td><td>134  </td><td>137  </td><td> 13  </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>132  </td><td>0.007</td><td>0.000</td><td>0.008</td><td>0.000</td><td>0    </td><td>0.000</td><td>16   </td><td>2.4  </td><td> 0   </td><td>...  </td><td> 53  </td><td>170  </td><td> 9   </td><td>0    </td><td>137  </td><td>136  </td><td>138  </td><td> 11  </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>134  </td><td>0.001</td><td>0.000</td><td>0.010</td><td>0.009</td><td>0    </td><td>0.002</td><td>26   </td><td>5.9  </td><td> 0   </td><td>...  </td><td> 50  </td><td>200  </td><td> 5   </td><td>3    </td><td> 76  </td><td>107  </td><td>107  </td><td>170  </td><td> 0   </td><td>3    </td></tr>\n",
       "\t<tr><td>134  </td><td>0.001</td><td>0.000</td><td>0.013</td><td>0.008</td><td>0    </td><td>0.003</td><td>29   </td><td>6.3  </td><td> 0   </td><td>...  </td><td> 50  </td><td>200  </td><td> 6   </td><td>3    </td><td> 71  </td><td>107  </td><td>106  </td><td>215  </td><td> 0   </td><td>3    </td></tr>\n",
       "\t<tr><td>122  </td><td>0.000</td><td>0.000</td><td>0.000</td><td>0.000</td><td>0    </td><td>0.000</td><td>83   </td><td>0.5  </td><td> 6   </td><td>...  </td><td> 62  </td><td>130  </td><td> 0   </td><td>0    </td><td>122  </td><td>122  </td><td>123  </td><td>  3  </td><td> 1   </td><td>3    </td></tr>\n",
       "\t<tr><td>122  </td><td>0.000</td><td>0.000</td><td>0.002</td><td>0.000</td><td>0    </td><td>0.000</td><td>84   </td><td>0.5  </td><td> 5   </td><td>...  </td><td> 62  </td><td>130  </td><td> 0   </td><td>0    </td><td>122  </td><td>122  </td><td>123  </td><td>  3  </td><td> 1   </td><td>3    </td></tr>\n",
       "\t<tr><td>122  </td><td>0.000</td><td>0.000</td><td>0.003</td><td>0.000</td><td>0    </td><td>0.000</td><td>86   </td><td>0.3  </td><td> 6   </td><td>...  </td><td> 62  </td><td>130  </td><td> 1   </td><td>0    </td><td>122  </td><td>122  </td><td>123  </td><td>  1  </td><td> 1   </td><td>3    </td></tr>\n",
       "\t<tr><td>151  </td><td>0.000</td><td>0.000</td><td>0.001</td><td>0.001</td><td>0    </td><td>0.000</td><td>64   </td><td>1.9  </td><td> 9   </td><td>...  </td><td> 56  </td><td>186  </td><td> 2   </td><td>0    </td><td>150  </td><td>148  </td><td>151  </td><td>  9  </td><td> 1   </td><td>2    </td></tr>\n",
       "\t<tr><td>150  </td><td>0.000</td><td>0.000</td><td>0.001</td><td>0.001</td><td>0    </td><td>0.000</td><td>64   </td><td>2.0  </td><td> 8   </td><td>...  </td><td> 56  </td><td>186  </td><td> 5   </td><td>0    </td><td>150  </td><td>148  </td><td>151  </td><td> 10  </td><td> 1   </td><td>2    </td></tr>\n",
       "\t<tr><td>131  </td><td>0.005</td><td>0.072</td><td>0.008</td><td>0.003</td><td>0    </td><td>0.000</td><td>28   </td><td>1.4  </td><td> 0   </td><td>...  </td><td> 88  </td><td>154  </td><td> 5   </td><td>0    </td><td>135  </td><td>134  </td><td>137  </td><td>  7  </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>131  </td><td>0.009</td><td>0.222</td><td>0.006</td><td>0.002</td><td>0    </td><td>0.000</td><td>28   </td><td>1.5  </td><td> 0   </td><td>...  </td><td> 71  </td><td>158  </td><td> 2   </td><td>0    </td><td>141  </td><td>137  </td><td>141  </td><td> 10  </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>130  </td><td>0.006</td><td>0.408</td><td>0.004</td><td>0.005</td><td>0    </td><td>0.001</td><td>21   </td><td>2.3  </td><td> 0   </td><td>...  </td><td> 67  </td><td>174  </td><td> 7   </td><td>0    </td><td>143  </td><td>125  </td><td>135  </td><td> 76  </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>130  </td><td>0.006</td><td>0.380</td><td>0.004</td><td>0.004</td><td>0    </td><td>0.001</td><td>19   </td><td>2.3  </td><td> 0   </td><td>...  </td><td> 67  </td><td>174  </td><td> 3   </td><td>0    </td><td>134  </td><td>127  </td><td>133  </td><td> 43  </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>130  </td><td>0.006</td><td>0.441</td><td>0.005</td><td>0.005</td><td>0    </td><td>0.000</td><td>24   </td><td>2.1  </td><td> 0   </td><td>...  </td><td> 53  </td><td>178  </td><td> 5   </td><td>0    </td><td>143  </td><td>128  </td><td>138  </td><td> 70  </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>131  </td><td>0.002</td><td>0.383</td><td>0.003</td><td>0.005</td><td>0    </td><td>0.002</td><td>18   </td><td>2.4  </td><td> 0   </td><td>...  </td><td> 67  </td><td>174  </td><td> 5   </td><td>0    </td><td>134  </td><td>125  </td><td>132  </td><td> 45  </td><td> 0   </td><td>2    </td></tr>\n",
       "\t<tr><td>130  </td><td>0.003</td><td>0.451</td><td>0.006</td><td>0.004</td><td>0    </td><td>0.001</td><td>23   </td><td>1.9  </td><td> 0   </td><td>...  </td><td> 59  </td><td>158  </td><td> 6   </td><td>0    </td><td>133  </td><td>124  </td><td>129  </td><td> 36  </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>130  </td><td>0.005</td><td>0.469</td><td>0.005</td><td>0.004</td><td>0    </td><td>0.001</td><td>29   </td><td>1.7  </td><td> 0   </td><td>...  </td><td> 65  </td><td>177  </td><td> 6   </td><td>1    </td><td>133  </td><td>129  </td><td>133  </td><td> 27  </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>129  </td><td>0.000</td><td>0.340</td><td>0.004</td><td>0.002</td><td>0    </td><td>0.003</td><td>30   </td><td>2.1  </td><td> 0   </td><td>...  </td><td> 54  </td><td>182  </td><td>13   </td><td>0    </td><td>129  </td><td>104  </td><td>120  </td><td>138  </td><td> 0   </td><td>3    </td></tr>\n",
       "\t<tr><td>128  </td><td>0.005</td><td>0.425</td><td>0.003</td><td>0.003</td><td>0    </td><td>0.002</td><td>26   </td><td>1.7  </td><td> 0   </td><td>...  </td><td> 57  </td><td>198  </td><td> 9   </td><td>0    </td><td>129  </td><td>125  </td><td>132  </td><td> 34  </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>128  </td><td>0.000</td><td>0.334</td><td>0.003</td><td>0.003</td><td>0    </td><td>0.003</td><td>34   </td><td>2.5  </td><td> 0   </td><td>...  </td><td> 54  </td><td>199  </td><td>11   </td><td>1    </td><td> 75  </td><td> 99  </td><td>102  </td><td>148  </td><td>-1   </td><td>3    </td></tr>\n",
       "\t<tr><td>128  </td><td>0.000</td><td>0.000</td><td>0.000</td><td>0.000</td><td>0    </td><td>0.000</td><td>80   </td><td>0.5  </td><td> 0   </td><td>...  </td><td>114  </td><td>130  </td><td> 0   </td><td>0    </td><td>126  </td><td>124  </td><td>125  </td><td>  1  </td><td> 1   </td><td>3    </td></tr>\n",
       "\t<tr><td>128  </td><td>0.000</td><td>0.000</td><td>0.003</td><td>0.000</td><td>0    </td><td>0.000</td><td>86   </td><td>0.3  </td><td>79   </td><td>...  </td><td>114  </td><td>130  </td><td> 0   </td><td>0    </td><td>128  </td><td>126  </td><td>129  </td><td>  0  </td><td> 1   </td><td>3    </td></tr>\n",
       "\t<tr><td>124  </td><td>0.000</td><td>0.000</td><td>0.000</td><td>0.000</td><td>0    </td><td>0.000</td><td>86   </td><td>0.3  </td><td>72   </td><td>...  </td><td>118  </td><td>130  </td><td> 1   </td><td>0    </td><td>124  </td><td>124  </td><td>125  </td><td>  0  </td><td> 0   </td><td>3    </td></tr>\n",
       "\t<tr><td>124  </td><td>0.000</td><td>0.000</td><td>0.000</td><td>0.000</td><td>0    </td><td>0.000</td><td>86   </td><td>0.4  </td><td>14   </td><td>...  </td><td>122  </td><td>146  </td><td> 1   </td><td>0    </td><td>126  </td><td>126  </td><td>127  </td><td>  0  </td><td>-1   </td><td>3    </td></tr>\n",
       "\t<tr><td>124  </td><td>0.000</td><td>0.000</td><td>0.000</td><td>0.000</td><td>0    </td><td>0.000</td><td>87   </td><td>0.2  </td><td>71   </td><td>...  </td><td>118  </td><td>128  </td><td> 0   </td><td>0    </td><td>124  </td><td>123  </td><td>125  </td><td>  0  </td><td> 0   </td><td>3    </td></tr>\n",
       "\t<tr><td>132  </td><td>0.000</td><td>0.135</td><td>0.001</td><td>0.008</td><td>0    </td><td>0.001</td><td>29   </td><td>4.4  </td><td> 0   </td><td>...  </td><td> 50  </td><td>191  </td><td> 7   </td><td>1    </td><td>133  </td><td>119  </td><td>129  </td><td> 73  </td><td> 0   </td><td>2    </td></tr>\n",
       "\t<tr><td>132  </td><td>0.000</td><td>0.099</td><td>0.000</td><td>0.012</td><td>0    </td><td>0.000</td><td>26   </td><td>6.0  </td><td> 0   </td><td>...  </td><td> 50  </td><td>193  </td><td>10   </td><td>0    </td><td>133  </td><td>113  </td><td>117  </td><td> 89  </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>   </td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>133  </td><td>0.000</td><td>0.000</td><td>0.007</td><td>0.000</td><td>0    </td><td>0.000</td><td>75   </td><td>0.4  </td><td>15   </td><td>...  </td><td>129  </td><td>155  </td><td> 2   </td><td>0    </td><td>136  </td><td>137  </td><td>139  </td><td> 1   </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>133  </td><td>0.000</td><td>0.000</td><td>0.005</td><td>0.000</td><td>0    </td><td>0.000</td><td>75   </td><td>0.6  </td><td>20   </td><td>...  </td><td>129  </td><td>155  </td><td> 2   </td><td>0    </td><td>136  </td><td>136  </td><td>138  </td><td> 0   </td><td>-1   </td><td>1    </td></tr>\n",
       "\t<tr><td>133  </td><td>0.000</td><td>0.004</td><td>0.006</td><td>0.000</td><td>0    </td><td>0.000</td><td>73   </td><td>1.6  </td><td>14   </td><td>...  </td><td>123  </td><td>155  </td><td> 3   </td><td>0    </td><td>136  </td><td>133  </td><td>137  </td><td> 1   </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>133  </td><td>0.000</td><td>0.009</td><td>0.005</td><td>0.000</td><td>0    </td><td>0.000</td><td>72   </td><td>2.1  </td><td>11   </td><td>...  </td><td> 91  </td><td>151  </td><td>10   </td><td>0    </td><td>136  </td><td>132  </td><td>136  </td><td> 1   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>133  </td><td>0.000</td><td>0.010</td><td>0.005</td><td>0.000</td><td>0    </td><td>0.000</td><td>70   </td><td>2.7  </td><td> 4   </td><td>...  </td><td> 91  </td><td>151  </td><td> 8   </td><td>1    </td><td>134  </td><td>130  </td><td>135  </td><td> 1   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>133  </td><td>0.000</td><td>0.009</td><td>0.008</td><td>0.000</td><td>0    </td><td>0.000</td><td>69   </td><td>3.0  </td><td> 1   </td><td>...  </td><td> 91  </td><td>148  </td><td> 8   </td><td>0    </td><td>134  </td><td>128  </td><td>134  </td><td> 2   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>133  </td><td>0.000</td><td>0.006</td><td>0.007</td><td>0.000</td><td>0    </td><td>0.000</td><td>68   </td><td>3.0  </td><td> 1   </td><td>...  </td><td> 91  </td><td>148  </td><td> 8   </td><td>0    </td><td>133  </td><td>129  </td><td>134  </td><td> 2   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>133  </td><td>0.000</td><td>0.001</td><td>0.008</td><td>0.000</td><td>0    </td><td>0.000</td><td>70   </td><td>2.0  </td><td> 6   </td><td>...  </td><td> 91  </td><td>159  </td><td> 7   </td><td>1    </td><td>133  </td><td>132  </td><td>135  </td><td> 3   </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.000</td><td>0.009</td><td>0.000</td><td>0    </td><td>0.000</td><td>78   </td><td>0.4  </td><td>27   </td><td>...  </td><td>112  </td><td>155  </td><td> 4   </td><td>0    </td><td>138  </td><td>137  </td><td>139  </td><td> 0   </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.000</td><td>0.009</td><td>0.000</td><td>0    </td><td>0.000</td><td>79   </td><td>0.2  </td><td>40   </td><td>...  </td><td>129  </td><td>149  </td><td> 2   </td><td>0    </td><td>138  </td><td>138  </td><td>139  </td><td> 0   </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.001</td><td>0.008</td><td>0.000</td><td>0    </td><td>0.000</td><td>78   </td><td>0.4  </td><td>36   </td><td>...  </td><td>113  </td><td>149  </td><td> 3   </td><td>0    </td><td>139  </td><td>137  </td><td>139  </td><td> 1   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.001</td><td>0.006</td><td>0.000</td><td>0    </td><td>0.000</td><td>74   </td><td>1.0  </td><td>21   </td><td>...  </td><td>107  </td><td>149  </td><td> 2   </td><td>0    </td><td>137  </td><td>135  </td><td>138  </td><td> 1   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.003</td><td>0.008</td><td>0.001</td><td>0    </td><td>0.000</td><td>67   </td><td>2.2  </td><td> 0   </td><td>...  </td><td>100  </td><td>145  </td><td> 3   </td><td>0    </td><td>133  </td><td>131  </td><td>136  </td><td> 2   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.001</td><td>0.008</td><td>0.001</td><td>0    </td><td>0.000</td><td>67   </td><td>1.9  </td><td> 0   </td><td>...  </td><td>100  </td><td>145  </td><td> 2   </td><td>0    </td><td>135  </td><td>132  </td><td>136  </td><td> 2   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.004</td><td>0.008</td><td>0.007</td><td>0    </td><td>0.001</td><td>64   </td><td>2.2  </td><td> 0   </td><td>...  </td><td> 67  </td><td>152  </td><td> 5   </td><td>0    </td><td>134  </td><td>119  </td><td>131  </td><td>45   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.004</td><td>0.009</td><td>0.009</td><td>0    </td><td>0.002</td><td>63   </td><td>2.2  </td><td> 0   </td><td>...  </td><td> 67  </td><td>153  </td><td> 6   </td><td>0    </td><td>134  </td><td>112  </td><td>123  </td><td>71   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.005</td><td>0.006</td><td>0.008</td><td>0    </td><td>0.002</td><td>63   </td><td>2.2  </td><td> 0   </td><td>...  </td><td> 67  </td><td>152  </td><td> 6   </td><td>0    </td><td>134  </td><td>116  </td><td>128  </td><td>53   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>136  </td><td>0.000</td><td>0.002</td><td>0.008</td><td>0.000</td><td>0    </td><td>0.000</td><td>67   </td><td>1.5  </td><td>11   </td><td>...  </td><td>115  </td><td>153  </td><td> 4   </td><td>0    </td><td>140  </td><td>133  </td><td>138  </td><td> 4   </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>137  </td><td>0.000</td><td>0.000</td><td>0.007</td><td>0.000</td><td>0    </td><td>0.000</td><td>81   </td><td>0.4  </td><td>33   </td><td>...  </td><td>121  </td><td>152  </td><td> 2   </td><td>0    </td><td>146  </td><td>143  </td><td>145  </td><td> 1   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.000</td><td>0.000</td><td>0.006</td><td>0.000</td><td>0    </td><td>0.000</td><td>83   </td><td>0.2  </td><td>48   </td><td>...  </td><td>132  </td><td>152  </td><td> 2   </td><td>0    </td><td>145  </td><td>145  </td><td>146  </td><td> 0   </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.004</td><td>0.000</td><td>0.004</td><td>0.000</td><td>0    </td><td>0.000</td><td>80   </td><td>0.2  </td><td>36   </td><td>...  </td><td>140  </td><td>158  </td><td> 1   </td><td>0    </td><td>147  </td><td>148  </td><td>149  </td><td> 1   </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.000</td><td>0.000</td><td>0.008</td><td>0.000</td><td>0    </td><td>0.000</td><td>79   </td><td>0.3  </td><td>20   </td><td>...  </td><td>124  </td><td>150  </td><td> 1   </td><td>0    </td><td>144  </td><td>143  </td><td>145  </td><td> 1   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.000</td><td>0.000</td><td>0.006</td><td>0.001</td><td>0    </td><td>0.000</td><td>79   </td><td>0.5  </td><td>26   </td><td>...  </td><td>129  </td><td>150  </td><td> 1   </td><td>0    </td><td>145  </td><td>142  </td><td>145  </td><td> 2   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.000</td><td>0.000</td><td>0.007</td><td>0.001</td><td>0    </td><td>0.000</td><td>79   </td><td>0.6  </td><td>27   </td><td>...  </td><td>124  </td><td>150  </td><td> 1   </td><td>0    </td><td>144  </td><td>141  </td><td>145  </td><td> 1   </td><td> 1   </td><td>1    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.000</td><td>0.000</td><td>0.005</td><td>0.001</td><td>0    </td><td>0.000</td><td>77   </td><td>0.7  </td><td>17   </td><td>...  </td><td>124  </td><td>155  </td><td> 2   </td><td>0    </td><td>145  </td><td>143  </td><td>145  </td><td> 2   </td><td> 0   </td><td>1    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.000</td><td>0.000</td><td>0.007</td><td>0.000</td><td>0    </td><td>0.000</td><td>79   </td><td>0.2  </td><td>25   </td><td>...  </td><td>137  </td><td>177  </td><td> 4   </td><td>0    </td><td>153  </td><td>150  </td><td>152  </td><td> 2   </td><td> 0   </td><td>2    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.001</td><td>0.000</td><td>0.007</td><td>0.000</td><td>0    </td><td>0.000</td><td>78   </td><td>0.4  </td><td>22   </td><td>...  </td><td>103  </td><td>169  </td><td> 6   </td><td>0    </td><td>152  </td><td>148  </td><td>151  </td><td> 3   </td><td> 1   </td><td>2    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.001</td><td>0.000</td><td>0.007</td><td>0.000</td><td>0    </td><td>0.000</td><td>79   </td><td>0.4  </td><td>20   </td><td>...  </td><td>103  </td><td>170  </td><td> 5   </td><td>0    </td><td>153  </td><td>148  </td><td>152  </td><td> 4   </td><td> 1   </td><td>2    </td></tr>\n",
       "\t<tr><td>140  </td><td>0.001</td><td>0.000</td><td>0.006</td><td>0.000</td><td>0    </td><td>0.000</td><td>78   </td><td>0.4  </td><td>27   </td><td>...  </td><td>103  </td><td>169  </td><td> 6   </td><td>0    </td><td>152  </td><td>147  </td><td>151  </td><td> 4   </td><td> 1   </td><td>2    </td></tr>\n",
       "\t<tr><td>142  </td><td>0.002</td><td>0.002</td><td>0.008</td><td>0.000</td><td>0    </td><td>0.000</td><td>74   </td><td>0.4  </td><td>36   </td><td>...  </td><td>117  </td><td>159  </td><td> 2   </td><td>1    </td><td>145  </td><td>143  </td><td>145  </td><td> 1   </td><td> 0   </td><td>1    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllll}\n",
       " LB & AC & FM & UC & DL & DS & DP & ASTV & MSTV & ALTV & ... & Min & Max & Nmax & Nzeros & Mode & Mean & Median & Variance & Tendency & NSP\\\\\n",
       "\\hline\n",
       "\t 120   & 0.000 & 0.000 & 0.000 & 0.000 & 0     & 0.000 & 73    & 0.5   & 43    & ...   &  62   & 126   &  2    & 0     & 120   & 137   & 121   &  73   &  1    & 2    \\\\\n",
       "\t 132   & 0.006 & 0.000 & 0.006 & 0.003 & 0     & 0.000 & 17    & 2.1   &  0    & ...   &  68   & 198   &  6    & 1     & 141   & 136   & 140   &  12   &  0    & 1    \\\\\n",
       "\t 133   & 0.003 & 0.000 & 0.008 & 0.003 & 0     & 0.000 & 16    & 2.1   &  0    & ...   &  68   & 198   &  5    & 1     & 141   & 135   & 138   &  13   &  0    & 1    \\\\\n",
       "\t 134   & 0.003 & 0.000 & 0.008 & 0.003 & 0     & 0.000 & 16    & 2.4   &  0    & ...   &  53   & 170   & 11    & 0     & 137   & 134   & 137   &  13   &  1    & 1    \\\\\n",
       "\t 132   & 0.007 & 0.000 & 0.008 & 0.000 & 0     & 0.000 & 16    & 2.4   &  0    & ...   &  53   & 170   &  9    & 0     & 137   & 136   & 138   &  11   &  1    & 1    \\\\\n",
       "\t 134   & 0.001 & 0.000 & 0.010 & 0.009 & 0     & 0.002 & 26    & 5.9   &  0    & ...   &  50   & 200   &  5    & 3     &  76   & 107   & 107   & 170   &  0    & 3    \\\\\n",
       "\t 134   & 0.001 & 0.000 & 0.013 & 0.008 & 0     & 0.003 & 29    & 6.3   &  0    & ...   &  50   & 200   &  6    & 3     &  71   & 107   & 106   & 215   &  0    & 3    \\\\\n",
       "\t 122   & 0.000 & 0.000 & 0.000 & 0.000 & 0     & 0.000 & 83    & 0.5   &  6    & ...   &  62   & 130   &  0    & 0     & 122   & 122   & 123   &   3   &  1    & 3    \\\\\n",
       "\t 122   & 0.000 & 0.000 & 0.002 & 0.000 & 0     & 0.000 & 84    & 0.5   &  5    & ...   &  62   & 130   &  0    & 0     & 122   & 122   & 123   &   3   &  1    & 3    \\\\\n",
       "\t 122   & 0.000 & 0.000 & 0.003 & 0.000 & 0     & 0.000 & 86    & 0.3   &  6    & ...   &  62   & 130   &  1    & 0     & 122   & 122   & 123   &   1   &  1    & 3    \\\\\n",
       "\t 151   & 0.000 & 0.000 & 0.001 & 0.001 & 0     & 0.000 & 64    & 1.9   &  9    & ...   &  56   & 186   &  2    & 0     & 150   & 148   & 151   &   9   &  1    & 2    \\\\\n",
       "\t 150   & 0.000 & 0.000 & 0.001 & 0.001 & 0     & 0.000 & 64    & 2.0   &  8    & ...   &  56   & 186   &  5    & 0     & 150   & 148   & 151   &  10   &  1    & 2    \\\\\n",
       "\t 131   & 0.005 & 0.072 & 0.008 & 0.003 & 0     & 0.000 & 28    & 1.4   &  0    & ...   &  88   & 154   &  5    & 0     & 135   & 134   & 137   &   7   &  1    & 1    \\\\\n",
       "\t 131   & 0.009 & 0.222 & 0.006 & 0.002 & 0     & 0.000 & 28    & 1.5   &  0    & ...   &  71   & 158   &  2    & 0     & 141   & 137   & 141   &  10   &  1    & 1    \\\\\n",
       "\t 130   & 0.006 & 0.408 & 0.004 & 0.005 & 0     & 0.001 & 21    & 2.3   &  0    & ...   &  67   & 174   &  7    & 0     & 143   & 125   & 135   &  76   &  0    & 1    \\\\\n",
       "\t 130   & 0.006 & 0.380 & 0.004 & 0.004 & 0     & 0.001 & 19    & 2.3   &  0    & ...   &  67   & 174   &  3    & 0     & 134   & 127   & 133   &  43   &  0    & 1    \\\\\n",
       "\t 130   & 0.006 & 0.441 & 0.005 & 0.005 & 0     & 0.000 & 24    & 2.1   &  0    & ...   &  53   & 178   &  5    & 0     & 143   & 128   & 138   &  70   &  1    & 1    \\\\\n",
       "\t 131   & 0.002 & 0.383 & 0.003 & 0.005 & 0     & 0.002 & 18    & 2.4   &  0    & ...   &  67   & 174   &  5    & 0     & 134   & 125   & 132   &  45   &  0    & 2    \\\\\n",
       "\t 130   & 0.003 & 0.451 & 0.006 & 0.004 & 0     & 0.001 & 23    & 1.9   &  0    & ...   &  59   & 158   &  6    & 0     & 133   & 124   & 129   &  36   &  1    & 1    \\\\\n",
       "\t 130   & 0.005 & 0.469 & 0.005 & 0.004 & 0     & 0.001 & 29    & 1.7   &  0    & ...   &  65   & 177   &  6    & 1     & 133   & 129   & 133   &  27   &  0    & 1    \\\\\n",
       "\t 129   & 0.000 & 0.340 & 0.004 & 0.002 & 0     & 0.003 & 30    & 2.1   &  0    & ...   &  54   & 182   & 13    & 0     & 129   & 104   & 120   & 138   &  0    & 3    \\\\\n",
       "\t 128   & 0.005 & 0.425 & 0.003 & 0.003 & 0     & 0.002 & 26    & 1.7   &  0    & ...   &  57   & 198   &  9    & 0     & 129   & 125   & 132   &  34   &  0    & 1    \\\\\n",
       "\t 128   & 0.000 & 0.334 & 0.003 & 0.003 & 0     & 0.003 & 34    & 2.5   &  0    & ...   &  54   & 199   & 11    & 1     &  75   &  99   & 102   & 148   & -1    & 3    \\\\\n",
       "\t 128   & 0.000 & 0.000 & 0.000 & 0.000 & 0     & 0.000 & 80    & 0.5   &  0    & ...   & 114   & 130   &  0    & 0     & 126   & 124   & 125   &   1   &  1    & 3    \\\\\n",
       "\t 128   & 0.000 & 0.000 & 0.003 & 0.000 & 0     & 0.000 & 86    & 0.3   & 79    & ...   & 114   & 130   &  0    & 0     & 128   & 126   & 129   &   0   &  1    & 3    \\\\\n",
       "\t 124   & 0.000 & 0.000 & 0.000 & 0.000 & 0     & 0.000 & 86    & 0.3   & 72    & ...   & 118   & 130   &  1    & 0     & 124   & 124   & 125   &   0   &  0    & 3    \\\\\n",
       "\t 124   & 0.000 & 0.000 & 0.000 & 0.000 & 0     & 0.000 & 86    & 0.4   & 14    & ...   & 122   & 146   &  1    & 0     & 126   & 126   & 127   &   0   & -1    & 3    \\\\\n",
       "\t 124   & 0.000 & 0.000 & 0.000 & 0.000 & 0     & 0.000 & 87    & 0.2   & 71    & ...   & 118   & 128   &  0    & 0     & 124   & 123   & 125   &   0   &  0    & 3    \\\\\n",
       "\t 132   & 0.000 & 0.135 & 0.001 & 0.008 & 0     & 0.001 & 29    & 4.4   &  0    & ...   &  50   & 191   &  7    & 1     & 133   & 119   & 129   &  73   &  0    & 2    \\\\\n",
       "\t 132   & 0.000 & 0.099 & 0.000 & 0.012 & 0     & 0.000 & 26    & 6.0   &  0    & ...   &  50   & 193   & 10    & 0     & 133   & 113   & 117   &  89   &  0    & 1    \\\\\n",
       "\t ... & ... & ... & ... & ... & ... & ... & ... & ... & ... &     & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
       "\t 133   & 0.000 & 0.000 & 0.007 & 0.000 & 0     & 0.000 & 75    & 0.4   & 15    & ...   & 129   & 155   &  2    & 0     & 136   & 137   & 139   &  1    &  0    & 1    \\\\\n",
       "\t 133   & 0.000 & 0.000 & 0.005 & 0.000 & 0     & 0.000 & 75    & 0.6   & 20    & ...   & 129   & 155   &  2    & 0     & 136   & 136   & 138   &  0    & -1    & 1    \\\\\n",
       "\t 133   & 0.000 & 0.004 & 0.006 & 0.000 & 0     & 0.000 & 73    & 1.6   & 14    & ...   & 123   & 155   &  3    & 0     & 136   & 133   & 137   &  1    &  0    & 1    \\\\\n",
       "\t 133   & 0.000 & 0.009 & 0.005 & 0.000 & 0     & 0.000 & 72    & 2.1   & 11    & ...   &  91   & 151   & 10    & 0     & 136   & 132   & 136   &  1    &  1    & 1    \\\\\n",
       "\t 133   & 0.000 & 0.010 & 0.005 & 0.000 & 0     & 0.000 & 70    & 2.7   &  4    & ...   &  91   & 151   &  8    & 1     & 134   & 130   & 135   &  1    &  1    & 1    \\\\\n",
       "\t 133   & 0.000 & 0.009 & 0.008 & 0.000 & 0     & 0.000 & 69    & 3.0   &  1    & ...   &  91   & 148   &  8    & 0     & 134   & 128   & 134   &  2    &  1    & 1    \\\\\n",
       "\t 133   & 0.000 & 0.006 & 0.007 & 0.000 & 0     & 0.000 & 68    & 3.0   &  1    & ...   &  91   & 148   &  8    & 0     & 133   & 129   & 134   &  2    &  1    & 1    \\\\\n",
       "\t 133   & 0.000 & 0.001 & 0.008 & 0.000 & 0     & 0.000 & 70    & 2.0   &  6    & ...   &  91   & 159   &  7    & 1     & 133   & 132   & 135   &  3    &  0    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.000 & 0.009 & 0.000 & 0     & 0.000 & 78    & 0.4   & 27    & ...   & 112   & 155   &  4    & 0     & 138   & 137   & 139   &  0    &  0    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.000 & 0.009 & 0.000 & 0     & 0.000 & 79    & 0.2   & 40    & ...   & 129   & 149   &  2    & 0     & 138   & 138   & 139   &  0    &  0    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.001 & 0.008 & 0.000 & 0     & 0.000 & 78    & 0.4   & 36    & ...   & 113   & 149   &  3    & 0     & 139   & 137   & 139   &  1    &  1    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.001 & 0.006 & 0.000 & 0     & 0.000 & 74    & 1.0   & 21    & ...   & 107   & 149   &  2    & 0     & 137   & 135   & 138   &  1    &  1    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.003 & 0.008 & 0.001 & 0     & 0.000 & 67    & 2.2   &  0    & ...   & 100   & 145   &  3    & 0     & 133   & 131   & 136   &  2    &  1    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.001 & 0.008 & 0.001 & 0     & 0.000 & 67    & 1.9   &  0    & ...   & 100   & 145   &  2    & 0     & 135   & 132   & 136   &  2    &  1    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.004 & 0.008 & 0.007 & 0     & 0.001 & 64    & 2.2   &  0    & ...   &  67   & 152   &  5    & 0     & 134   & 119   & 131   & 45    &  1    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.004 & 0.009 & 0.009 & 0     & 0.002 & 63    & 2.2   &  0    & ...   &  67   & 153   &  6    & 0     & 134   & 112   & 123   & 71    &  1    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.005 & 0.006 & 0.008 & 0     & 0.002 & 63    & 2.2   &  0    & ...   &  67   & 152   &  6    & 0     & 134   & 116   & 128   & 53    &  1    & 1    \\\\\n",
       "\t 136   & 0.000 & 0.002 & 0.008 & 0.000 & 0     & 0.000 & 67    & 1.5   & 11    & ...   & 115   & 153   &  4    & 0     & 140   & 133   & 138   &  4    &  0    & 1    \\\\\n",
       "\t 137   & 0.000 & 0.000 & 0.007 & 0.000 & 0     & 0.000 & 81    & 0.4   & 33    & ...   & 121   & 152   &  2    & 0     & 146   & 143   & 145   &  1    &  1    & 1    \\\\\n",
       "\t 140   & 0.000 & 0.000 & 0.006 & 0.000 & 0     & 0.000 & 83    & 0.2   & 48    & ...   & 132   & 152   &  2    & 0     & 145   & 145   & 146   &  0    &  0    & 1    \\\\\n",
       "\t 140   & 0.004 & 0.000 & 0.004 & 0.000 & 0     & 0.000 & 80    & 0.2   & 36    & ...   & 140   & 158   &  1    & 0     & 147   & 148   & 149   &  1    &  0    & 1    \\\\\n",
       "\t 140   & 0.000 & 0.000 & 0.008 & 0.000 & 0     & 0.000 & 79    & 0.3   & 20    & ...   & 124   & 150   &  1    & 0     & 144   & 143   & 145   &  1    &  1    & 1    \\\\\n",
       "\t 140   & 0.000 & 0.000 & 0.006 & 0.001 & 0     & 0.000 & 79    & 0.5   & 26    & ...   & 129   & 150   &  1    & 0     & 145   & 142   & 145   &  2    &  1    & 1    \\\\\n",
       "\t 140   & 0.000 & 0.000 & 0.007 & 0.001 & 0     & 0.000 & 79    & 0.6   & 27    & ...   & 124   & 150   &  1    & 0     & 144   & 141   & 145   &  1    &  1    & 1    \\\\\n",
       "\t 140   & 0.000 & 0.000 & 0.005 & 0.001 & 0     & 0.000 & 77    & 0.7   & 17    & ...   & 124   & 155   &  2    & 0     & 145   & 143   & 145   &  2    &  0    & 1    \\\\\n",
       "\t 140   & 0.000 & 0.000 & 0.007 & 0.000 & 0     & 0.000 & 79    & 0.2   & 25    & ...   & 137   & 177   &  4    & 0     & 153   & 150   & 152   &  2    &  0    & 2    \\\\\n",
       "\t 140   & 0.001 & 0.000 & 0.007 & 0.000 & 0     & 0.000 & 78    & 0.4   & 22    & ...   & 103   & 169   &  6    & 0     & 152   & 148   & 151   &  3    &  1    & 2    \\\\\n",
       "\t 140   & 0.001 & 0.000 & 0.007 & 0.000 & 0     & 0.000 & 79    & 0.4   & 20    & ...   & 103   & 170   &  5    & 0     & 153   & 148   & 152   &  4    &  1    & 2    \\\\\n",
       "\t 140   & 0.001 & 0.000 & 0.006 & 0.000 & 0     & 0.000 & 78    & 0.4   & 27    & ...   & 103   & 169   &  6    & 0     & 152   & 147   & 151   &  4    &  1    & 2    \\\\\n",
       "\t 142   & 0.002 & 0.002 & 0.008 & 0.000 & 0     & 0.000 & 74    & 0.4   & 36    & ...   & 117   & 159   &  2    & 1     & 145   & 143   & 145   &  1    &  0    & 1    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| LB | AC | FM | UC | DL | DS | DP | ASTV | MSTV | ALTV | ... | Min | Max | Nmax | Nzeros | Mode | Mean | Median | Variance | Tendency | NSP |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 120   | 0.000 | 0.000 | 0.000 | 0.000 | 0     | 0.000 | 73    | 0.5   | 43    | ...   |  62   | 126   |  2    | 0     | 120   | 137   | 121   |  73   |  1    | 2     |\n",
       "| 132   | 0.006 | 0.000 | 0.006 | 0.003 | 0     | 0.000 | 17    | 2.1   |  0    | ...   |  68   | 198   |  6    | 1     | 141   | 136   | 140   |  12   |  0    | 1     |\n",
       "| 133   | 0.003 | 0.000 | 0.008 | 0.003 | 0     | 0.000 | 16    | 2.1   |  0    | ...   |  68   | 198   |  5    | 1     | 141   | 135   | 138   |  13   |  0    | 1     |\n",
       "| 134   | 0.003 | 0.000 | 0.008 | 0.003 | 0     | 0.000 | 16    | 2.4   |  0    | ...   |  53   | 170   | 11    | 0     | 137   | 134   | 137   |  13   |  1    | 1     |\n",
       "| 132   | 0.007 | 0.000 | 0.008 | 0.000 | 0     | 0.000 | 16    | 2.4   |  0    | ...   |  53   | 170   |  9    | 0     | 137   | 136   | 138   |  11   |  1    | 1     |\n",
       "| 134   | 0.001 | 0.000 | 0.010 | 0.009 | 0     | 0.002 | 26    | 5.9   |  0    | ...   |  50   | 200   |  5    | 3     |  76   | 107   | 107   | 170   |  0    | 3     |\n",
       "| 134   | 0.001 | 0.000 | 0.013 | 0.008 | 0     | 0.003 | 29    | 6.3   |  0    | ...   |  50   | 200   |  6    | 3     |  71   | 107   | 106   | 215   |  0    | 3     |\n",
       "| 122   | 0.000 | 0.000 | 0.000 | 0.000 | 0     | 0.000 | 83    | 0.5   |  6    | ...   |  62   | 130   |  0    | 0     | 122   | 122   | 123   |   3   |  1    | 3     |\n",
       "| 122   | 0.000 | 0.000 | 0.002 | 0.000 | 0     | 0.000 | 84    | 0.5   |  5    | ...   |  62   | 130   |  0    | 0     | 122   | 122   | 123   |   3   |  1    | 3     |\n",
       "| 122   | 0.000 | 0.000 | 0.003 | 0.000 | 0     | 0.000 | 86    | 0.3   |  6    | ...   |  62   | 130   |  1    | 0     | 122   | 122   | 123   |   1   |  1    | 3     |\n",
       "| 151   | 0.000 | 0.000 | 0.001 | 0.001 | 0     | 0.000 | 64    | 1.9   |  9    | ...   |  56   | 186   |  2    | 0     | 150   | 148   | 151   |   9   |  1    | 2     |\n",
       "| 150   | 0.000 | 0.000 | 0.001 | 0.001 | 0     | 0.000 | 64    | 2.0   |  8    | ...   |  56   | 186   |  5    | 0     | 150   | 148   | 151   |  10   |  1    | 2     |\n",
       "| 131   | 0.005 | 0.072 | 0.008 | 0.003 | 0     | 0.000 | 28    | 1.4   |  0    | ...   |  88   | 154   |  5    | 0     | 135   | 134   | 137   |   7   |  1    | 1     |\n",
       "| 131   | 0.009 | 0.222 | 0.006 | 0.002 | 0     | 0.000 | 28    | 1.5   |  0    | ...   |  71   | 158   |  2    | 0     | 141   | 137   | 141   |  10   |  1    | 1     |\n",
       "| 130   | 0.006 | 0.408 | 0.004 | 0.005 | 0     | 0.001 | 21    | 2.3   |  0    | ...   |  67   | 174   |  7    | 0     | 143   | 125   | 135   |  76   |  0    | 1     |\n",
       "| 130   | 0.006 | 0.380 | 0.004 | 0.004 | 0     | 0.001 | 19    | 2.3   |  0    | ...   |  67   | 174   |  3    | 0     | 134   | 127   | 133   |  43   |  0    | 1     |\n",
       "| 130   | 0.006 | 0.441 | 0.005 | 0.005 | 0     | 0.000 | 24    | 2.1   |  0    | ...   |  53   | 178   |  5    | 0     | 143   | 128   | 138   |  70   |  1    | 1     |\n",
       "| 131   | 0.002 | 0.383 | 0.003 | 0.005 | 0     | 0.002 | 18    | 2.4   |  0    | ...   |  67   | 174   |  5    | 0     | 134   | 125   | 132   |  45   |  0    | 2     |\n",
       "| 130   | 0.003 | 0.451 | 0.006 | 0.004 | 0     | 0.001 | 23    | 1.9   |  0    | ...   |  59   | 158   |  6    | 0     | 133   | 124   | 129   |  36   |  1    | 1     |\n",
       "| 130   | 0.005 | 0.469 | 0.005 | 0.004 | 0     | 0.001 | 29    | 1.7   |  0    | ...   |  65   | 177   |  6    | 1     | 133   | 129   | 133   |  27   |  0    | 1     |\n",
       "| 129   | 0.000 | 0.340 | 0.004 | 0.002 | 0     | 0.003 | 30    | 2.1   |  0    | ...   |  54   | 182   | 13    | 0     | 129   | 104   | 120   | 138   |  0    | 3     |\n",
       "| 128   | 0.005 | 0.425 | 0.003 | 0.003 | 0     | 0.002 | 26    | 1.7   |  0    | ...   |  57   | 198   |  9    | 0     | 129   | 125   | 132   |  34   |  0    | 1     |\n",
       "| 128   | 0.000 | 0.334 | 0.003 | 0.003 | 0     | 0.003 | 34    | 2.5   |  0    | ...   |  54   | 199   | 11    | 1     |  75   |  99   | 102   | 148   | -1    | 3     |\n",
       "| 128   | 0.000 | 0.000 | 0.000 | 0.000 | 0     | 0.000 | 80    | 0.5   |  0    | ...   | 114   | 130   |  0    | 0     | 126   | 124   | 125   |   1   |  1    | 3     |\n",
       "| 128   | 0.000 | 0.000 | 0.003 | 0.000 | 0     | 0.000 | 86    | 0.3   | 79    | ...   | 114   | 130   |  0    | 0     | 128   | 126   | 129   |   0   |  1    | 3     |\n",
       "| 124   | 0.000 | 0.000 | 0.000 | 0.000 | 0     | 0.000 | 86    | 0.3   | 72    | ...   | 118   | 130   |  1    | 0     | 124   | 124   | 125   |   0   |  0    | 3     |\n",
       "| 124   | 0.000 | 0.000 | 0.000 | 0.000 | 0     | 0.000 | 86    | 0.4   | 14    | ...   | 122   | 146   |  1    | 0     | 126   | 126   | 127   |   0   | -1    | 3     |\n",
       "| 124   | 0.000 | 0.000 | 0.000 | 0.000 | 0     | 0.000 | 87    | 0.2   | 71    | ...   | 118   | 128   |  0    | 0     | 124   | 123   | 125   |   0   |  0    | 3     |\n",
       "| 132   | 0.000 | 0.135 | 0.001 | 0.008 | 0     | 0.001 | 29    | 4.4   |  0    | ...   |  50   | 191   |  7    | 1     | 133   | 119   | 129   |  73   |  0    | 2     |\n",
       "| 132   | 0.000 | 0.099 | 0.000 | 0.012 | 0     | 0.000 | 26    | 6.0   |  0    | ...   |  50   | 193   | 10    | 0     | 133   | 113   | 117   |  89   |  0    | 1     |\n",
       "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |     | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
       "| 133   | 0.000 | 0.000 | 0.007 | 0.000 | 0     | 0.000 | 75    | 0.4   | 15    | ...   | 129   | 155   |  2    | 0     | 136   | 137   | 139   |  1    |  0    | 1     |\n",
       "| 133   | 0.000 | 0.000 | 0.005 | 0.000 | 0     | 0.000 | 75    | 0.6   | 20    | ...   | 129   | 155   |  2    | 0     | 136   | 136   | 138   |  0    | -1    | 1     |\n",
       "| 133   | 0.000 | 0.004 | 0.006 | 0.000 | 0     | 0.000 | 73    | 1.6   | 14    | ...   | 123   | 155   |  3    | 0     | 136   | 133   | 137   |  1    |  0    | 1     |\n",
       "| 133   | 0.000 | 0.009 | 0.005 | 0.000 | 0     | 0.000 | 72    | 2.1   | 11    | ...   |  91   | 151   | 10    | 0     | 136   | 132   | 136   |  1    |  1    | 1     |\n",
       "| 133   | 0.000 | 0.010 | 0.005 | 0.000 | 0     | 0.000 | 70    | 2.7   |  4    | ...   |  91   | 151   |  8    | 1     | 134   | 130   | 135   |  1    |  1    | 1     |\n",
       "| 133   | 0.000 | 0.009 | 0.008 | 0.000 | 0     | 0.000 | 69    | 3.0   |  1    | ...   |  91   | 148   |  8    | 0     | 134   | 128   | 134   |  2    |  1    | 1     |\n",
       "| 133   | 0.000 | 0.006 | 0.007 | 0.000 | 0     | 0.000 | 68    | 3.0   |  1    | ...   |  91   | 148   |  8    | 0     | 133   | 129   | 134   |  2    |  1    | 1     |\n",
       "| 133   | 0.000 | 0.001 | 0.008 | 0.000 | 0     | 0.000 | 70    | 2.0   |  6    | ...   |  91   | 159   |  7    | 1     | 133   | 132   | 135   |  3    |  0    | 1     |\n",
       "| 136   | 0.000 | 0.000 | 0.009 | 0.000 | 0     | 0.000 | 78    | 0.4   | 27    | ...   | 112   | 155   |  4    | 0     | 138   | 137   | 139   |  0    |  0    | 1     |\n",
       "| 136   | 0.000 | 0.000 | 0.009 | 0.000 | 0     | 0.000 | 79    | 0.2   | 40    | ...   | 129   | 149   |  2    | 0     | 138   | 138   | 139   |  0    |  0    | 1     |\n",
       "| 136   | 0.000 | 0.001 | 0.008 | 0.000 | 0     | 0.000 | 78    | 0.4   | 36    | ...   | 113   | 149   |  3    | 0     | 139   | 137   | 139   |  1    |  1    | 1     |\n",
       "| 136   | 0.000 | 0.001 | 0.006 | 0.000 | 0     | 0.000 | 74    | 1.0   | 21    | ...   | 107   | 149   |  2    | 0     | 137   | 135   | 138   |  1    |  1    | 1     |\n",
       "| 136   | 0.000 | 0.003 | 0.008 | 0.001 | 0     | 0.000 | 67    | 2.2   |  0    | ...   | 100   | 145   |  3    | 0     | 133   | 131   | 136   |  2    |  1    | 1     |\n",
       "| 136   | 0.000 | 0.001 | 0.008 | 0.001 | 0     | 0.000 | 67    | 1.9   |  0    | ...   | 100   | 145   |  2    | 0     | 135   | 132   | 136   |  2    |  1    | 1     |\n",
       "| 136   | 0.000 | 0.004 | 0.008 | 0.007 | 0     | 0.001 | 64    | 2.2   |  0    | ...   |  67   | 152   |  5    | 0     | 134   | 119   | 131   | 45    |  1    | 1     |\n",
       "| 136   | 0.000 | 0.004 | 0.009 | 0.009 | 0     | 0.002 | 63    | 2.2   |  0    | ...   |  67   | 153   |  6    | 0     | 134   | 112   | 123   | 71    |  1    | 1     |\n",
       "| 136   | 0.000 | 0.005 | 0.006 | 0.008 | 0     | 0.002 | 63    | 2.2   |  0    | ...   |  67   | 152   |  6    | 0     | 134   | 116   | 128   | 53    |  1    | 1     |\n",
       "| 136   | 0.000 | 0.002 | 0.008 | 0.000 | 0     | 0.000 | 67    | 1.5   | 11    | ...   | 115   | 153   |  4    | 0     | 140   | 133   | 138   |  4    |  0    | 1     |\n",
       "| 137   | 0.000 | 0.000 | 0.007 | 0.000 | 0     | 0.000 | 81    | 0.4   | 33    | ...   | 121   | 152   |  2    | 0     | 146   | 143   | 145   |  1    |  1    | 1     |\n",
       "| 140   | 0.000 | 0.000 | 0.006 | 0.000 | 0     | 0.000 | 83    | 0.2   | 48    | ...   | 132   | 152   |  2    | 0     | 145   | 145   | 146   |  0    |  0    | 1     |\n",
       "| 140   | 0.004 | 0.000 | 0.004 | 0.000 | 0     | 0.000 | 80    | 0.2   | 36    | ...   | 140   | 158   |  1    | 0     | 147   | 148   | 149   |  1    |  0    | 1     |\n",
       "| 140   | 0.000 | 0.000 | 0.008 | 0.000 | 0     | 0.000 | 79    | 0.3   | 20    | ...   | 124   | 150   |  1    | 0     | 144   | 143   | 145   |  1    |  1    | 1     |\n",
       "| 140   | 0.000 | 0.000 | 0.006 | 0.001 | 0     | 0.000 | 79    | 0.5   | 26    | ...   | 129   | 150   |  1    | 0     | 145   | 142   | 145   |  2    |  1    | 1     |\n",
       "| 140   | 0.000 | 0.000 | 0.007 | 0.001 | 0     | 0.000 | 79    | 0.6   | 27    | ...   | 124   | 150   |  1    | 0     | 144   | 141   | 145   |  1    |  1    | 1     |\n",
       "| 140   | 0.000 | 0.000 | 0.005 | 0.001 | 0     | 0.000 | 77    | 0.7   | 17    | ...   | 124   | 155   |  2    | 0     | 145   | 143   | 145   |  2    |  0    | 1     |\n",
       "| 140   | 0.000 | 0.000 | 0.007 | 0.000 | 0     | 0.000 | 79    | 0.2   | 25    | ...   | 137   | 177   |  4    | 0     | 153   | 150   | 152   |  2    |  0    | 2     |\n",
       "| 140   | 0.001 | 0.000 | 0.007 | 0.000 | 0     | 0.000 | 78    | 0.4   | 22    | ...   | 103   | 169   |  6    | 0     | 152   | 148   | 151   |  3    |  1    | 2     |\n",
       "| 140   | 0.001 | 0.000 | 0.007 | 0.000 | 0     | 0.000 | 79    | 0.4   | 20    | ...   | 103   | 170   |  5    | 0     | 153   | 148   | 152   |  4    |  1    | 2     |\n",
       "| 140   | 0.001 | 0.000 | 0.006 | 0.000 | 0     | 0.000 | 78    | 0.4   | 27    | ...   | 103   | 169   |  6    | 0     | 152   | 147   | 151   |  4    |  1    | 2     |\n",
       "| 142   | 0.002 | 0.002 | 0.008 | 0.000 | 0     | 0.000 | 74    | 0.4   | 36    | ...   | 117   | 159   |  2    | 1     | 145   | 143   | 145   |  1    |  0    | 1     |\n",
       "\n"
      ],
      "text/plain": [
       "     LB  AC    FM    UC    DL    DS  DP    ASTV MSTV ALTV ... Min Max Nmax\n",
       "1    120 0.000 0.000 0.000 0.000 0   0.000 73   0.5  43   ...  62 126  2  \n",
       "2    132 0.006 0.000 0.006 0.003 0   0.000 17   2.1   0   ...  68 198  6  \n",
       "3    133 0.003 0.000 0.008 0.003 0   0.000 16   2.1   0   ...  68 198  5  \n",
       "4    134 0.003 0.000 0.008 0.003 0   0.000 16   2.4   0   ...  53 170 11  \n",
       "5    132 0.007 0.000 0.008 0.000 0   0.000 16   2.4   0   ...  53 170  9  \n",
       "6    134 0.001 0.000 0.010 0.009 0   0.002 26   5.9   0   ...  50 200  5  \n",
       "7    134 0.001 0.000 0.013 0.008 0   0.003 29   6.3   0   ...  50 200  6  \n",
       "8    122 0.000 0.000 0.000 0.000 0   0.000 83   0.5   6   ...  62 130  0  \n",
       "9    122 0.000 0.000 0.002 0.000 0   0.000 84   0.5   5   ...  62 130  0  \n",
       "10   122 0.000 0.000 0.003 0.000 0   0.000 86   0.3   6   ...  62 130  1  \n",
       "11   151 0.000 0.000 0.001 0.001 0   0.000 64   1.9   9   ...  56 186  2  \n",
       "12   150 0.000 0.000 0.001 0.001 0   0.000 64   2.0   8   ...  56 186  5  \n",
       "13   131 0.005 0.072 0.008 0.003 0   0.000 28   1.4   0   ...  88 154  5  \n",
       "14   131 0.009 0.222 0.006 0.002 0   0.000 28   1.5   0   ...  71 158  2  \n",
       "15   130 0.006 0.408 0.004 0.005 0   0.001 21   2.3   0   ...  67 174  7  \n",
       "16   130 0.006 0.380 0.004 0.004 0   0.001 19   2.3   0   ...  67 174  3  \n",
       "17   130 0.006 0.441 0.005 0.005 0   0.000 24   2.1   0   ...  53 178  5  \n",
       "18   131 0.002 0.383 0.003 0.005 0   0.002 18   2.4   0   ...  67 174  5  \n",
       "19   130 0.003 0.451 0.006 0.004 0   0.001 23   1.9   0   ...  59 158  6  \n",
       "20   130 0.005 0.469 0.005 0.004 0   0.001 29   1.7   0   ...  65 177  6  \n",
       "21   129 0.000 0.340 0.004 0.002 0   0.003 30   2.1   0   ...  54 182 13  \n",
       "22   128 0.005 0.425 0.003 0.003 0   0.002 26   1.7   0   ...  57 198  9  \n",
       "23   128 0.000 0.334 0.003 0.003 0   0.003 34   2.5   0   ...  54 199 11  \n",
       "24   128 0.000 0.000 0.000 0.000 0   0.000 80   0.5   0   ... 114 130  0  \n",
       "25   128 0.000 0.000 0.003 0.000 0   0.000 86   0.3  79   ... 114 130  0  \n",
       "26   124 0.000 0.000 0.000 0.000 0   0.000 86   0.3  72   ... 118 130  1  \n",
       "27   124 0.000 0.000 0.000 0.000 0   0.000 86   0.4  14   ... 122 146  1  \n",
       "28   124 0.000 0.000 0.000 0.000 0   0.000 87   0.2  71   ... 118 128  0  \n",
       "29   132 0.000 0.135 0.001 0.008 0   0.001 29   4.4   0   ...  50 191  7  \n",
       "30   132 0.000 0.099 0.000 0.012 0   0.000 26   6.0   0   ...  50 193 10  \n",
       "...  ... ...   ...   ...   ...   ... ...   ...  ...  ...      ... ... ... \n",
       "2097 133 0.000 0.000 0.007 0.000 0   0.000 75   0.4  15   ... 129 155  2  \n",
       "2098 133 0.000 0.000 0.005 0.000 0   0.000 75   0.6  20   ... 129 155  2  \n",
       "2099 133 0.000 0.004 0.006 0.000 0   0.000 73   1.6  14   ... 123 155  3  \n",
       "2100 133 0.000 0.009 0.005 0.000 0   0.000 72   2.1  11   ...  91 151 10  \n",
       "2101 133 0.000 0.010 0.005 0.000 0   0.000 70   2.7   4   ...  91 151  8  \n",
       "2102 133 0.000 0.009 0.008 0.000 0   0.000 69   3.0   1   ...  91 148  8  \n",
       "2103 133 0.000 0.006 0.007 0.000 0   0.000 68   3.0   1   ...  91 148  8  \n",
       "2104 133 0.000 0.001 0.008 0.000 0   0.000 70   2.0   6   ...  91 159  7  \n",
       "2105 136 0.000 0.000 0.009 0.000 0   0.000 78   0.4  27   ... 112 155  4  \n",
       "2106 136 0.000 0.000 0.009 0.000 0   0.000 79   0.2  40   ... 129 149  2  \n",
       "2107 136 0.000 0.001 0.008 0.000 0   0.000 78   0.4  36   ... 113 149  3  \n",
       "2108 136 0.000 0.001 0.006 0.000 0   0.000 74   1.0  21   ... 107 149  2  \n",
       "2109 136 0.000 0.003 0.008 0.001 0   0.000 67   2.2   0   ... 100 145  3  \n",
       "2110 136 0.000 0.001 0.008 0.001 0   0.000 67   1.9   0   ... 100 145  2  \n",
       "2111 136 0.000 0.004 0.008 0.007 0   0.001 64   2.2   0   ...  67 152  5  \n",
       "2112 136 0.000 0.004 0.009 0.009 0   0.002 63   2.2   0   ...  67 153  6  \n",
       "2113 136 0.000 0.005 0.006 0.008 0   0.002 63   2.2   0   ...  67 152  6  \n",
       "2114 136 0.000 0.002 0.008 0.000 0   0.000 67   1.5  11   ... 115 153  4  \n",
       "2115 137 0.000 0.000 0.007 0.000 0   0.000 81   0.4  33   ... 121 152  2  \n",
       "2116 140 0.000 0.000 0.006 0.000 0   0.000 83   0.2  48   ... 132 152  2  \n",
       "2117 140 0.004 0.000 0.004 0.000 0   0.000 80   0.2  36   ... 140 158  1  \n",
       "2118 140 0.000 0.000 0.008 0.000 0   0.000 79   0.3  20   ... 124 150  1  \n",
       "2119 140 0.000 0.000 0.006 0.001 0   0.000 79   0.5  26   ... 129 150  1  \n",
       "2120 140 0.000 0.000 0.007 0.001 0   0.000 79   0.6  27   ... 124 150  1  \n",
       "2121 140 0.000 0.000 0.005 0.001 0   0.000 77   0.7  17   ... 124 155  2  \n",
       "2122 140 0.000 0.000 0.007 0.000 0   0.000 79   0.2  25   ... 137 177  4  \n",
       "2123 140 0.001 0.000 0.007 0.000 0   0.000 78   0.4  22   ... 103 169  6  \n",
       "2124 140 0.001 0.000 0.007 0.000 0   0.000 79   0.4  20   ... 103 170  5  \n",
       "2125 140 0.001 0.000 0.006 0.000 0   0.000 78   0.4  27   ... 103 169  6  \n",
       "2126 142 0.002 0.002 0.008 0.000 0   0.000 74   0.4  36   ... 117 159  2  \n",
       "     Nzeros Mode Mean Median Variance Tendency NSP\n",
       "1    0      120  137  121     73       1       2  \n",
       "2    1      141  136  140     12       0       1  \n",
       "3    1      141  135  138     13       0       1  \n",
       "4    0      137  134  137     13       1       1  \n",
       "5    0      137  136  138     11       1       1  \n",
       "6    3       76  107  107    170       0       3  \n",
       "7    3       71  107  106    215       0       3  \n",
       "8    0      122  122  123      3       1       3  \n",
       "9    0      122  122  123      3       1       3  \n",
       "10   0      122  122  123      1       1       3  \n",
       "11   0      150  148  151      9       1       2  \n",
       "12   0      150  148  151     10       1       2  \n",
       "13   0      135  134  137      7       1       1  \n",
       "14   0      141  137  141     10       1       1  \n",
       "15   0      143  125  135     76       0       1  \n",
       "16   0      134  127  133     43       0       1  \n",
       "17   0      143  128  138     70       1       1  \n",
       "18   0      134  125  132     45       0       2  \n",
       "19   0      133  124  129     36       1       1  \n",
       "20   1      133  129  133     27       0       1  \n",
       "21   0      129  104  120    138       0       3  \n",
       "22   0      129  125  132     34       0       1  \n",
       "23   1       75   99  102    148      -1       3  \n",
       "24   0      126  124  125      1       1       3  \n",
       "25   0      128  126  129      0       1       3  \n",
       "26   0      124  124  125      0       0       3  \n",
       "27   0      126  126  127      0      -1       3  \n",
       "28   0      124  123  125      0       0       3  \n",
       "29   1      133  119  129     73       0       2  \n",
       "30   0      133  113  117     89       0       1  \n",
       "...  ...    ...  ...  ...    ...      ...      ...\n",
       "2097 0      136  137  139     1        0       1  \n",
       "2098 0      136  136  138     0       -1       1  \n",
       "2099 0      136  133  137     1        0       1  \n",
       "2100 0      136  132  136     1        1       1  \n",
       "2101 1      134  130  135     1        1       1  \n",
       "2102 0      134  128  134     2        1       1  \n",
       "2103 0      133  129  134     2        1       1  \n",
       "2104 1      133  132  135     3        0       1  \n",
       "2105 0      138  137  139     0        0       1  \n",
       "2106 0      138  138  139     0        0       1  \n",
       "2107 0      139  137  139     1        1       1  \n",
       "2108 0      137  135  138     1        1       1  \n",
       "2109 0      133  131  136     2        1       1  \n",
       "2110 0      135  132  136     2        1       1  \n",
       "2111 0      134  119  131    45        1       1  \n",
       "2112 0      134  112  123    71        1       1  \n",
       "2113 0      134  116  128    53        1       1  \n",
       "2114 0      140  133  138     4        0       1  \n",
       "2115 0      146  143  145     1        1       1  \n",
       "2116 0      145  145  146     0        0       1  \n",
       "2117 0      147  148  149     1        0       1  \n",
       "2118 0      144  143  145     1        1       1  \n",
       "2119 0      145  142  145     2        1       1  \n",
       "2120 0      144  141  145     1        1       1  \n",
       "2121 0      145  143  145     2        0       1  \n",
       "2122 0      153  150  152     2        0       2  \n",
       "2123 0      152  148  151     3        1       2  \n",
       "2124 0      153  148  152     4        1       2  \n",
       "2125 0      152  147  151     4        1       2  \n",
       "2126 1      145  143  145     1        0       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2126</li>\n",
       "\t<li>22</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2126\n",
       "\\item 22\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2126\n",
       "2. 22\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2126   22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1 = read_excel(\"CTG.xlsx\")\n",
    "data1\n",
    "dim(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "trainIndex = createDataPartition(data1$NSP, p = 0.7, list = FALSE)\n",
    "data1_train_1 = data1[trainIndex, ]\n",
    "data1_test_1 = data1[-trainIndex, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "1489 samples\n",
       "  21 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 1340, 1340, 1340, 1340, 1340, 1340, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda  RMSE       Rsquared   MAE      \n",
       "  0.0     0.3855612  0.6035901  0.2728190\n",
       "  0.5     0.6102455        NaN  0.4704885\n",
       "  1.0     0.6102455        NaN  0.4704885\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were alpha = 1 and lambda = 0."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(2)\n",
    "data1_glm_model <- train(NSP ~ ., data = data1_train_1, method = \"glmnet\", trControl = fitControl, tuneGrid = glm_grid)\n",
    "data1_glm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "1489 samples\n",
       "  21 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 1340, 1340, 1341, 1340, 1340, 1340, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp    RMSE       Rsquared   MAE      \n",
       "  0.01  0.3250231  0.7050363  0.1465327\n",
       "  0.05  0.3889633  0.5860499  0.1986367\n",
       "  0.10  0.4137681  0.5312993  0.2188365\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1_dt_model <- train(NSP ~ ., data = data1_train_1, method = \"rpart\", trControl = fitControl, tuneGrid = dt_grid)\n",
    "data1_dt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
      "\"The response has five or fewer unique values.  Are you sure you want to do regression?\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       "1489 samples\n",
       "  21 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 1341, 1340, 1340, 1340, 1340, 1340, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  RMSE       Rsquared   MAE      \n",
       "  3     0.2466033  0.8415650  0.1217866\n",
       "  5     0.2412926  0.8460644  0.1118235\n",
       "  7     0.2397466  0.8470367  0.1067509\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was mtry = 7."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1_rf_model = train(NSP ~ ., data = data1_train_1, method = \"rf\", trControl = fitControl,tuneGrid = rf_grid)\n",
    "data1_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3550             nan     0.0500    0.0245\n",
      "     2        0.3310             nan     0.0500    0.0240\n",
      "     3        0.3058             nan     0.0500    0.0231\n",
      "     4        0.2832             nan     0.0500    0.0205\n",
      "     5        0.2633             nan     0.0500    0.0205\n",
      "     6        0.2456             nan     0.0500    0.0171\n",
      "     7        0.2310             nan     0.0500    0.0150\n",
      "     8        0.2153             nan     0.0500    0.0144\n",
      "     9        0.2030             nan     0.0500    0.0113\n",
      "    10        0.1906             nan     0.0500    0.0107\n",
      "    20        0.1119             nan     0.0500    0.0038\n",
      "    40        0.0587             nan     0.0500    0.0006\n",
      "    60        0.0434             nan     0.0500    0.0002\n",
      "    80        0.0365             nan     0.0500    0.0000\n",
      "   100        0.0318             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3530             nan     0.0500    0.0275\n",
      "     2        0.3265             nan     0.0500    0.0220\n",
      "     3        0.3017             nan     0.0500    0.0242\n",
      "     4        0.2804             nan     0.0500    0.0197\n",
      "     5        0.2603             nan     0.0500    0.0178\n",
      "     6        0.2417             nan     0.0500    0.0162\n",
      "     7        0.2256             nan     0.0500    0.0147\n",
      "     8        0.2111             nan     0.0500    0.0138\n",
      "     9        0.1981             nan     0.0500    0.0112\n",
      "    10        0.1855             nan     0.0500    0.0122\n",
      "    20        0.1040             nan     0.0500    0.0055\n",
      "    40        0.0485             nan     0.0500    0.0009\n",
      "    60        0.0327             nan     0.0500    0.0001\n",
      "    80        0.0256             nan     0.0500   -0.0000\n",
      "   100        0.0217             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3266             nan     0.1000    0.0528\n",
      "     2        0.2813             nan     0.1000    0.0393\n",
      "     3        0.2428             nan     0.1000    0.0322\n",
      "     4        0.2115             nan     0.1000    0.0297\n",
      "     5        0.1861             nan     0.1000    0.0218\n",
      "     6        0.1646             nan     0.1000    0.0205\n",
      "     7        0.1480             nan     0.1000    0.0166\n",
      "     8        0.1324             nan     0.1000    0.0149\n",
      "     9        0.1210             nan     0.1000    0.0093\n",
      "    10        0.1098             nan     0.1000    0.0089\n",
      "    20        0.0568             nan     0.1000    0.0018\n",
      "    40        0.0355             nan     0.1000    0.0003\n",
      "    60        0.0282             nan     0.1000   -0.0002\n",
      "    80        0.0230             nan     0.1000   -0.0003\n",
      "   100        0.0194             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3251             nan     0.1000    0.0515\n",
      "     2        0.2811             nan     0.1000    0.0388\n",
      "     3        0.2430             nan     0.1000    0.0339\n",
      "     4        0.2127             nan     0.1000    0.0293\n",
      "     5        0.1847             nan     0.1000    0.0210\n",
      "     6        0.1620             nan     0.1000    0.0212\n",
      "     7        0.1433             nan     0.1000    0.0180\n",
      "     8        0.1268             nan     0.1000    0.0150\n",
      "     9        0.1137             nan     0.1000    0.0114\n",
      "    10        0.1016             nan     0.1000    0.0088\n",
      "    20        0.0474             nan     0.1000    0.0012\n",
      "    40        0.0268             nan     0.1000   -0.0002\n",
      "    60        0.0199             nan     0.1000   -0.0003\n",
      "    80        0.0153             nan     0.1000   -0.0002\n",
      "   100        0.0123             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3438             nan     0.0500    0.0227\n",
      "     2        0.3192             nan     0.0500    0.0245\n",
      "     3        0.2963             nan     0.0500    0.0203\n",
      "     4        0.2770             nan     0.0500    0.0179\n",
      "     5        0.2588             nan     0.0500    0.0170\n",
      "     6        0.2408             nan     0.0500    0.0180\n",
      "     7        0.2257             nan     0.0500    0.0162\n",
      "     8        0.2119             nan     0.0500    0.0129\n",
      "     9        0.2001             nan     0.0500    0.0115\n",
      "    10        0.1887             nan     0.0500    0.0102\n",
      "    20        0.1109             nan     0.0500    0.0049\n",
      "    40        0.0600             nan     0.0500    0.0008\n",
      "    60        0.0455             nan     0.0500    0.0001\n",
      "    80        0.0390             nan     0.0500    0.0000\n",
      "   100        0.0346             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3432             nan     0.0500    0.0265\n",
      "     2        0.3197             nan     0.0500    0.0231\n",
      "     3        0.2966             nan     0.0500    0.0197\n",
      "     4        0.2752             nan     0.0500    0.0199\n",
      "     5        0.2566             nan     0.0500    0.0168\n",
      "     6        0.2389             nan     0.0500    0.0168\n",
      "     7        0.2224             nan     0.0500    0.0140\n",
      "     8        0.2078             nan     0.0500    0.0134\n",
      "     9        0.1949             nan     0.0500    0.0112\n",
      "    10        0.1825             nan     0.0500    0.0098\n",
      "    20        0.1028             nan     0.0500    0.0044\n",
      "    40        0.0507             nan     0.0500    0.0010\n",
      "    60        0.0349             nan     0.0500    0.0001\n",
      "    80        0.0280             nan     0.0500   -0.0001\n",
      "   100        0.0238             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3167             nan     0.1000    0.0493\n",
      "     2        0.2732             nan     0.1000    0.0388\n",
      "     3        0.2395             nan     0.1000    0.0319\n",
      "     4        0.2085             nan     0.1000    0.0264\n",
      "     5        0.1844             nan     0.1000    0.0260\n",
      "     6        0.1646             nan     0.1000    0.0174\n",
      "     7        0.1477             nan     0.1000    0.0159\n",
      "     8        0.1326             nan     0.1000    0.0147\n",
      "     9        0.1203             nan     0.1000    0.0088\n",
      "    10        0.1104             nan     0.1000    0.0081\n",
      "    20        0.0601             nan     0.1000    0.0014\n",
      "    40        0.0382             nan     0.1000   -0.0002\n",
      "    60        0.0305             nan     0.1000   -0.0002\n",
      "    80        0.0261             nan     0.1000   -0.0001\n",
      "   100        0.0219             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3138             nan     0.1000    0.0538\n",
      "     2        0.2702             nan     0.1000    0.0397\n",
      "     3        0.2341             nan     0.1000    0.0325\n",
      "     4        0.2034             nan     0.1000    0.0288\n",
      "     5        0.1780             nan     0.1000    0.0206\n",
      "     6        0.1559             nan     0.1000    0.0204\n",
      "     7        0.1396             nan     0.1000    0.0157\n",
      "     8        0.1254             nan     0.1000    0.0121\n",
      "     9        0.1126             nan     0.1000    0.0115\n",
      "    10        0.1015             nan     0.1000    0.0100\n",
      "    20        0.0490             nan     0.1000    0.0015\n",
      "    40        0.0274             nan     0.1000   -0.0001\n",
      "    60        0.0208             nan     0.1000   -0.0003\n",
      "    80        0.0162             nan     0.1000   -0.0001\n",
      "   100        0.0129             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3367             nan     0.0500    0.0241\n",
      "     2        0.3131             nan     0.0500    0.0236\n",
      "     3        0.2925             nan     0.0500    0.0177\n",
      "     4        0.2732             nan     0.0500    0.0212\n",
      "     5        0.2546             nan     0.0500    0.0180\n",
      "     6        0.2392             nan     0.0500    0.0136\n",
      "     7        0.2234             nan     0.0500    0.0140\n",
      "     8        0.2092             nan     0.0500    0.0128\n",
      "     9        0.1957             nan     0.0500    0.0120\n",
      "    10        0.1835             nan     0.0500    0.0113\n",
      "    20        0.1070             nan     0.0500    0.0042\n",
      "    40        0.0567             nan     0.0500    0.0010\n",
      "    60        0.0427             nan     0.0500   -0.0000\n",
      "    80        0.0358             nan     0.0500    0.0000\n",
      "   100        0.0315             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3346             nan     0.0500    0.0239\n",
      "     2        0.3090             nan     0.0500    0.0284\n",
      "     3        0.2870             nan     0.0500    0.0213\n",
      "     4        0.2666             nan     0.0500    0.0190\n",
      "     5        0.2470             nan     0.0500    0.0182\n",
      "     6        0.2300             nan     0.0500    0.0158\n",
      "     7        0.2138             nan     0.0500    0.0172\n",
      "     8        0.2002             nan     0.0500    0.0119\n",
      "     9        0.1871             nan     0.0500    0.0129\n",
      "    10        0.1752             nan     0.0500    0.0105\n",
      "    20        0.0987             nan     0.0500    0.0036\n",
      "    40        0.0483             nan     0.0500    0.0008\n",
      "    60        0.0334             nan     0.0500   -0.0000\n",
      "    80        0.0268             nan     0.0500   -0.0002\n",
      "   100        0.0228             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3065             nan     0.1000    0.0450\n",
      "     2        0.2656             nan     0.1000    0.0431\n",
      "     3        0.2306             nan     0.1000    0.0350\n",
      "     4        0.2023             nan     0.1000    0.0291\n",
      "     5        0.1784             nan     0.1000    0.0235\n",
      "     6        0.1594             nan     0.1000    0.0170\n",
      "     7        0.1429             nan     0.1000    0.0142\n",
      "     8        0.1297             nan     0.1000    0.0139\n",
      "     9        0.1172             nan     0.1000    0.0101\n",
      "    10        0.1050             nan     0.1000    0.0087\n",
      "    20        0.0561             nan     0.1000    0.0018\n",
      "    40        0.0369             nan     0.1000    0.0001\n",
      "    60        0.0287             nan     0.1000   -0.0002\n",
      "    80        0.0238             nan     0.1000   -0.0002\n",
      "   100        0.0207             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3102             nan     0.1000    0.0487\n",
      "     2        0.2647             nan     0.1000    0.0426\n",
      "     3        0.2308             nan     0.1000    0.0335\n",
      "     4        0.2020             nan     0.1000    0.0274\n",
      "     5        0.1764             nan     0.1000    0.0234\n",
      "     6        0.1558             nan     0.1000    0.0187\n",
      "     7        0.1382             nan     0.1000    0.0152\n",
      "     8        0.1231             nan     0.1000    0.0113\n",
      "     9        0.1100             nan     0.1000    0.0103\n",
      "    10        0.0988             nan     0.1000    0.0109\n",
      "    20        0.0493             nan     0.1000    0.0013\n",
      "    40        0.0274             nan     0.1000   -0.0002\n",
      "    60        0.0205             nan     0.1000   -0.0004\n",
      "    80        0.0160             nan     0.1000   -0.0003\n",
      "   100        0.0125             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3537             nan     0.0500    0.0263\n",
      "     2        0.3287             nan     0.0500    0.0208\n",
      "     3        0.3061             nan     0.0500    0.0217\n",
      "     4        0.2846             nan     0.0500    0.0212\n",
      "     5        0.2657             nan     0.0500    0.0175\n",
      "     6        0.2485             nan     0.0500    0.0159\n",
      "     7        0.2322             nan     0.0500    0.0156\n",
      "     8        0.2172             nan     0.0500    0.0132\n",
      "     9        0.2039             nan     0.0500    0.0119\n",
      "    10        0.1915             nan     0.0500    0.0106\n",
      "    20        0.1113             nan     0.0500    0.0050\n",
      "    40        0.0591             nan     0.0500    0.0006\n",
      "    60        0.0440             nan     0.0500    0.0002\n",
      "    80        0.0372             nan     0.0500    0.0000\n",
      "   100        0.0324             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3545             nan     0.0500    0.0249\n",
      "     2        0.3264             nan     0.0500    0.0271\n",
      "     3        0.3017             nan     0.0500    0.0229\n",
      "     4        0.2817             nan     0.0500    0.0199\n",
      "     5        0.2610             nan     0.0500    0.0202\n",
      "     6        0.2430             nan     0.0500    0.0179\n",
      "     7        0.2249             nan     0.0500    0.0162\n",
      "     8        0.2103             nan     0.0500    0.0129\n",
      "     9        0.1955             nan     0.0500    0.0124\n",
      "    10        0.1829             nan     0.0500    0.0119\n",
      "    20        0.1014             nan     0.0500    0.0049\n",
      "    40        0.0474             nan     0.0500    0.0008\n",
      "    60        0.0333             nan     0.0500    0.0001\n",
      "    80        0.0261             nan     0.0500   -0.0001\n",
      "   100        0.0219             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3258             nan     0.1000    0.0563\n",
      "     2        0.2833             nan     0.1000    0.0412\n",
      "     3        0.2451             nan     0.1000    0.0376\n",
      "     4        0.2152             nan     0.1000    0.0298\n",
      "     5        0.1890             nan     0.1000    0.0270\n",
      "     6        0.1685             nan     0.1000    0.0194\n",
      "     7        0.1503             nan     0.1000    0.0166\n",
      "     8        0.1349             nan     0.1000    0.0129\n",
      "     9        0.1209             nan     0.1000    0.0096\n",
      "    10        0.1094             nan     0.1000    0.0101\n",
      "    20        0.0575             nan     0.1000    0.0013\n",
      "    40        0.0366             nan     0.1000   -0.0002\n",
      "    60        0.0288             nan     0.1000   -0.0003\n",
      "    80        0.0238             nan     0.1000   -0.0001\n",
      "   100        0.0199             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3235             nan     0.1000    0.0494\n",
      "     2        0.2741             nan     0.1000    0.0417\n",
      "     3        0.2375             nan     0.1000    0.0338\n",
      "     4        0.2057             nan     0.1000    0.0279\n",
      "     5        0.1793             nan     0.1000    0.0236\n",
      "     6        0.1576             nan     0.1000    0.0189\n",
      "     7        0.1402             nan     0.1000    0.0153\n",
      "     8        0.1263             nan     0.1000    0.0118\n",
      "     9        0.1139             nan     0.1000    0.0099\n",
      "    10        0.1017             nan     0.1000    0.0110\n",
      "    20        0.0482             nan     0.1000    0.0017\n",
      "    40        0.0266             nan     0.1000    0.0000\n",
      "    60        0.0192             nan     0.1000   -0.0002\n",
      "    80        0.0149             nan     0.1000   -0.0003\n",
      "   100        0.0119             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3357             nan     0.0500    0.0238\n",
      "     2        0.3123             nan     0.0500    0.0200\n",
      "     3        0.2911             nan     0.0500    0.0192\n",
      "     4        0.2709             nan     0.0500    0.0174\n",
      "     5        0.2545             nan     0.0500    0.0162\n",
      "     6        0.2367             nan     0.0500    0.0162\n",
      "     7        0.2216             nan     0.0500    0.0141\n",
      "     8        0.2080             nan     0.0500    0.0123\n",
      "     9        0.1954             nan     0.0500    0.0113\n",
      "    10        0.1841             nan     0.0500    0.0108\n",
      "    20        0.1071             nan     0.0500    0.0048\n",
      "    40        0.0557             nan     0.0500    0.0007\n",
      "    60        0.0411             nan     0.0500    0.0001\n",
      "    80        0.0346             nan     0.0500    0.0002\n",
      "   100        0.0308             nan     0.0500    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3359             nan     0.0500    0.0237\n",
      "     2        0.3100             nan     0.0500    0.0233\n",
      "     3        0.2899             nan     0.0500    0.0198\n",
      "     4        0.2699             nan     0.0500    0.0183\n",
      "     5        0.2501             nan     0.0500    0.0188\n",
      "     6        0.2323             nan     0.0500    0.0159\n",
      "     7        0.2170             nan     0.0500    0.0140\n",
      "     8        0.2034             nan     0.0500    0.0123\n",
      "     9        0.1900             nan     0.0500    0.0119\n",
      "    10        0.1779             nan     0.0500    0.0119\n",
      "    20        0.1010             nan     0.0500    0.0043\n",
      "    40        0.0478             nan     0.0500    0.0005\n",
      "    60        0.0323             nan     0.0500    0.0002\n",
      "    80        0.0255             nan     0.0500   -0.0000\n",
      "   100        0.0215             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3114             nan     0.1000    0.0499\n",
      "     2        0.2737             nan     0.1000    0.0382\n",
      "     3        0.2362             nan     0.1000    0.0327\n",
      "     4        0.2058             nan     0.1000    0.0289\n",
      "     5        0.1828             nan     0.1000    0.0185\n",
      "     6        0.1626             nan     0.1000    0.0189\n",
      "     7        0.1455             nan     0.1000    0.0132\n",
      "     8        0.1290             nan     0.1000    0.0129\n",
      "     9        0.1164             nan     0.1000    0.0110\n",
      "    10        0.1060             nan     0.1000    0.0087\n",
      "    20        0.0569             nan     0.1000    0.0012\n",
      "    40        0.0353             nan     0.1000   -0.0001\n",
      "    60        0.0283             nan     0.1000   -0.0003\n",
      "    80        0.0239             nan     0.1000   -0.0002\n",
      "   100        0.0204             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3099             nan     0.1000    0.0508\n",
      "     2        0.2709             nan     0.1000    0.0351\n",
      "     3        0.2333             nan     0.1000    0.0356\n",
      "     4        0.2028             nan     0.1000    0.0277\n",
      "     5        0.1774             nan     0.1000    0.0222\n",
      "     6        0.1558             nan     0.1000    0.0189\n",
      "     7        0.1390             nan     0.1000    0.0161\n",
      "     8        0.1240             nan     0.1000    0.0147\n",
      "     9        0.1103             nan     0.1000    0.0130\n",
      "    10        0.0985             nan     0.1000    0.0109\n",
      "    20        0.0481             nan     0.1000    0.0015\n",
      "    40        0.0275             nan     0.1000   -0.0003\n",
      "    60        0.0208             nan     0.1000   -0.0003\n",
      "    80        0.0164             nan     0.1000   -0.0003\n",
      "   100        0.0132             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3441             nan     0.0500    0.0237\n",
      "     2        0.3210             nan     0.0500    0.0238\n",
      "     3        0.2996             nan     0.0500    0.0213\n",
      "     4        0.2791             nan     0.0500    0.0174\n",
      "     5        0.2605             nan     0.0500    0.0136\n",
      "     6        0.2438             nan     0.0500    0.0176\n",
      "     7        0.2289             nan     0.0500    0.0132\n",
      "     8        0.2136             nan     0.0500    0.0142\n",
      "     9        0.2008             nan     0.0500    0.0118\n",
      "    10        0.1887             nan     0.0500    0.0103\n",
      "    20        0.1134             nan     0.0500    0.0049\n",
      "    40        0.0609             nan     0.0500    0.0007\n",
      "    60        0.0459             nan     0.0500    0.0000\n",
      "    80        0.0393             nan     0.0500   -0.0000\n",
      "   100        0.0351             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3418             nan     0.0500    0.0251\n",
      "     2        0.3165             nan     0.0500    0.0223\n",
      "     3        0.2941             nan     0.0500    0.0193\n",
      "     4        0.2734             nan     0.0500    0.0180\n",
      "     5        0.2542             nan     0.0500    0.0162\n",
      "     6        0.2377             nan     0.0500    0.0158\n",
      "     7        0.2213             nan     0.0500    0.0137\n",
      "     8        0.2075             nan     0.0500    0.0137\n",
      "     9        0.1949             nan     0.0500    0.0121\n",
      "    10        0.1817             nan     0.0500    0.0105\n",
      "    20        0.1041             nan     0.0500    0.0043\n",
      "    40        0.0512             nan     0.0500    0.0005\n",
      "    60        0.0362             nan     0.0500   -0.0001\n",
      "    80        0.0300             nan     0.0500   -0.0001\n",
      "   100        0.0252             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3189             nan     0.1000    0.0476\n",
      "     2        0.2763             nan     0.1000    0.0430\n",
      "     3        0.2406             nan     0.1000    0.0326\n",
      "     4        0.2102             nan     0.1000    0.0279\n",
      "     5        0.1857             nan     0.1000    0.0252\n",
      "     6        0.1658             nan     0.1000    0.0193\n",
      "     7        0.1475             nan     0.1000    0.0149\n",
      "     8        0.1326             nan     0.1000    0.0129\n",
      "     9        0.1209             nan     0.1000    0.0115\n",
      "    10        0.1125             nan     0.1000    0.0064\n",
      "    20        0.0600             nan     0.1000    0.0016\n",
      "    40        0.0392             nan     0.1000   -0.0001\n",
      "    60        0.0313             nan     0.1000    0.0000\n",
      "    80        0.0261             nan     0.1000   -0.0002\n",
      "   100        0.0227             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3160             nan     0.1000    0.0498\n",
      "     2        0.2694             nan     0.1000    0.0403\n",
      "     3        0.2349             nan     0.1000    0.0346\n",
      "     4        0.2037             nan     0.1000    0.0270\n",
      "     5        0.1788             nan     0.1000    0.0246\n",
      "     6        0.1552             nan     0.1000    0.0211\n",
      "     7        0.1393             nan     0.1000    0.0143\n",
      "     8        0.1258             nan     0.1000    0.0122\n",
      "     9        0.1134             nan     0.1000    0.0112\n",
      "    10        0.1032             nan     0.1000    0.0091\n",
      "    20        0.0522             nan     0.1000    0.0011\n",
      "    40        0.0305             nan     0.1000    0.0000\n",
      "    60        0.0219             nan     0.1000   -0.0002\n",
      "    80        0.0164             nan     0.1000   -0.0002\n",
      "   100        0.0130             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3495             nan     0.0500    0.0236\n",
      "     2        0.3272             nan     0.0500    0.0214\n",
      "     3        0.3041             nan     0.0500    0.0232\n",
      "     4        0.2840             nan     0.0500    0.0190\n",
      "     5        0.2648             nan     0.0500    0.0181\n",
      "     6        0.2470             nan     0.0500    0.0163\n",
      "     7        0.2314             nan     0.0500    0.0146\n",
      "     8        0.2174             nan     0.0500    0.0111\n",
      "     9        0.2036             nan     0.0500    0.0128\n",
      "    10        0.1918             nan     0.0500    0.0103\n",
      "    20        0.1124             nan     0.0500    0.0046\n",
      "    40        0.0604             nan     0.0500    0.0009\n",
      "    60        0.0458             nan     0.0500    0.0003\n",
      "    80        0.0385             nan     0.0500    0.0000\n",
      "   100        0.0338             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3473             nan     0.0500    0.0247\n",
      "     2        0.3223             nan     0.0500    0.0212\n",
      "     3        0.2979             nan     0.0500    0.0208\n",
      "     4        0.2785             nan     0.0500    0.0166\n",
      "     5        0.2597             nan     0.0500    0.0177\n",
      "     6        0.2411             nan     0.0500    0.0166\n",
      "     7        0.2247             nan     0.0500    0.0160\n",
      "     8        0.2092             nan     0.0500    0.0146\n",
      "     9        0.1962             nan     0.0500    0.0113\n",
      "    10        0.1835             nan     0.0500    0.0108\n",
      "    20        0.1025             nan     0.0500    0.0046\n",
      "    40        0.0513             nan     0.0500    0.0006\n",
      "    60        0.0360             nan     0.0500   -0.0000\n",
      "    80        0.0293             nan     0.0500   -0.0002\n",
      "   100        0.0248             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3197             nan     0.1000    0.0503\n",
      "     2        0.2754             nan     0.1000    0.0408\n",
      "     3        0.2398             nan     0.1000    0.0318\n",
      "     4        0.2112             nan     0.1000    0.0270\n",
      "     5        0.1864             nan     0.1000    0.0265\n",
      "     6        0.1652             nan     0.1000    0.0193\n",
      "     7        0.1487             nan     0.1000    0.0157\n",
      "     8        0.1344             nan     0.1000    0.0132\n",
      "     9        0.1223             nan     0.1000    0.0114\n",
      "    10        0.1122             nan     0.1000    0.0082\n",
      "    20        0.0609             nan     0.1000    0.0010\n",
      "    40        0.0388             nan     0.1000   -0.0000\n",
      "    60        0.0307             nan     0.1000   -0.0002\n",
      "    80        0.0256             nan     0.1000   -0.0000\n",
      "   100        0.0222             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3200             nan     0.1000    0.0519\n",
      "     2        0.2735             nan     0.1000    0.0450\n",
      "     3        0.2366             nan     0.1000    0.0348\n",
      "     4        0.2063             nan     0.1000    0.0240\n",
      "     5        0.1810             nan     0.1000    0.0242\n",
      "     6        0.1591             nan     0.1000    0.0193\n",
      "     7        0.1417             nan     0.1000    0.0132\n",
      "     8        0.1258             nan     0.1000    0.0126\n",
      "     9        0.1128             nan     0.1000    0.0097\n",
      "    10        0.1026             nan     0.1000    0.0084\n",
      "    20        0.0497             nan     0.1000    0.0018\n",
      "    40        0.0283             nan     0.1000   -0.0003\n",
      "    60        0.0206             nan     0.1000   -0.0001\n",
      "    80        0.0160             nan     0.1000   -0.0002\n",
      "   100        0.0131             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3467             nan     0.0500    0.0262\n",
      "     2        0.3197             nan     0.0500    0.0235\n",
      "     3        0.2960             nan     0.0500    0.0213\n",
      "     4        0.2760             nan     0.0500    0.0169\n",
      "     5        0.2564             nan     0.0500    0.0188\n",
      "     6        0.2399             nan     0.0500    0.0156\n",
      "     7        0.2240             nan     0.0500    0.0146\n",
      "     8        0.2105             nan     0.0500    0.0128\n",
      "     9        0.1974             nan     0.0500    0.0113\n",
      "    10        0.1859             nan     0.0500    0.0116\n",
      "    20        0.1105             nan     0.0500    0.0038\n",
      "    40        0.0594             nan     0.0500    0.0005\n",
      "    60        0.0449             nan     0.0500    0.0001\n",
      "    80        0.0377             nan     0.0500   -0.0001\n",
      "   100        0.0332             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3457             nan     0.0500    0.0284\n",
      "     2        0.3207             nan     0.0500    0.0227\n",
      "     3        0.2970             nan     0.0500    0.0246\n",
      "     4        0.2761             nan     0.0500    0.0222\n",
      "     5        0.2557             nan     0.0500    0.0181\n",
      "     6        0.2373             nan     0.0500    0.0159\n",
      "     7        0.2222             nan     0.0500    0.0137\n",
      "     8        0.2082             nan     0.0500    0.0132\n",
      "     9        0.1952             nan     0.0500    0.0112\n",
      "    10        0.1822             nan     0.0500    0.0108\n",
      "    20        0.1018             nan     0.0500    0.0045\n",
      "    40        0.0495             nan     0.0500    0.0007\n",
      "    60        0.0343             nan     0.0500   -0.0000\n",
      "    80        0.0275             nan     0.0500   -0.0001\n",
      "   100        0.0233             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3199             nan     0.1000    0.0475\n",
      "     2        0.2772             nan     0.1000    0.0441\n",
      "     3        0.2413             nan     0.1000    0.0357\n",
      "     4        0.2091             nan     0.1000    0.0306\n",
      "     5        0.1836             nan     0.1000    0.0245\n",
      "     6        0.1633             nan     0.1000    0.0181\n",
      "     7        0.1449             nan     0.1000    0.0162\n",
      "     8        0.1294             nan     0.1000    0.0146\n",
      "     9        0.1169             nan     0.1000    0.0107\n",
      "    10        0.1074             nan     0.1000    0.0081\n",
      "    20        0.0575             nan     0.1000    0.0014\n",
      "    40        0.0360             nan     0.1000    0.0000\n",
      "    60        0.0287             nan     0.1000   -0.0004\n",
      "    80        0.0238             nan     0.1000   -0.0002\n",
      "   100        0.0206             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3213             nan     0.1000    0.0477\n",
      "     2        0.2788             nan     0.1000    0.0415\n",
      "     3        0.2391             nan     0.1000    0.0388\n",
      "     4        0.2067             nan     0.1000    0.0322\n",
      "     5        0.1801             nan     0.1000    0.0228\n",
      "     6        0.1587             nan     0.1000    0.0188\n",
      "     7        0.1400             nan     0.1000    0.0150\n",
      "     8        0.1247             nan     0.1000    0.0142\n",
      "     9        0.1118             nan     0.1000    0.0097\n",
      "    10        0.1011             nan     0.1000    0.0088\n",
      "    20        0.0489             nan     0.1000    0.0017\n",
      "    40        0.0276             nan     0.1000   -0.0003\n",
      "    60        0.0202             nan     0.1000   -0.0003\n",
      "    80        0.0158             nan     0.1000   -0.0001\n",
      "   100        0.0128             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3504             nan     0.0500    0.0276\n",
      "     2        0.3262             nan     0.0500    0.0202\n",
      "     3        0.3032             nan     0.0500    0.0203\n",
      "     4        0.2829             nan     0.0500    0.0206\n",
      "     5        0.2641             nan     0.0500    0.0191\n",
      "     6        0.2470             nan     0.0500    0.0162\n",
      "     7        0.2305             nan     0.0500    0.0173\n",
      "     8        0.2170             nan     0.0500    0.0145\n",
      "     9        0.2031             nan     0.0500    0.0114\n",
      "    10        0.1906             nan     0.0500    0.0107\n",
      "    20        0.1107             nan     0.0500    0.0046\n",
      "    40        0.0585             nan     0.0500    0.0007\n",
      "    60        0.0445             nan     0.0500   -0.0000\n",
      "    80        0.0373             nan     0.0500    0.0000\n",
      "   100        0.0329             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3501             nan     0.0500    0.0288\n",
      "     2        0.3243             nan     0.0500    0.0240\n",
      "     3        0.3013             nan     0.0500    0.0217\n",
      "     4        0.2794             nan     0.0500    0.0195\n",
      "     5        0.2596             nan     0.0500    0.0180\n",
      "     6        0.2424             nan     0.0500    0.0153\n",
      "     7        0.2262             nan     0.0500    0.0144\n",
      "     8        0.2122             nan     0.0500    0.0136\n",
      "     9        0.1976             nan     0.0500    0.0134\n",
      "    10        0.1851             nan     0.0500    0.0118\n",
      "    20        0.1020             nan     0.0500    0.0040\n",
      "    40        0.0487             nan     0.0500    0.0004\n",
      "    60        0.0337             nan     0.0500    0.0000\n",
      "    80        0.0271             nan     0.0500   -0.0001\n",
      "   100        0.0230             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3233             nan     0.1000    0.0520\n",
      "     2        0.2800             nan     0.1000    0.0425\n",
      "     3        0.2444             nan     0.1000    0.0362\n",
      "     4        0.2138             nan     0.1000    0.0273\n",
      "     5        0.1873             nan     0.1000    0.0232\n",
      "     6        0.1637             nan     0.1000    0.0181\n",
      "     7        0.1467             nan     0.1000    0.0138\n",
      "     8        0.1325             nan     0.1000    0.0120\n",
      "     9        0.1208             nan     0.1000    0.0098\n",
      "    10        0.1095             nan     0.1000    0.0081\n",
      "    20        0.0598             nan     0.1000    0.0011\n",
      "    40        0.0381             nan     0.1000    0.0002\n",
      "    60        0.0302             nan     0.1000   -0.0002\n",
      "    80        0.0245             nan     0.1000   -0.0002\n",
      "   100        0.0206             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3258             nan     0.1000    0.0481\n",
      "     2        0.2809             nan     0.1000    0.0424\n",
      "     3        0.2445             nan     0.1000    0.0345\n",
      "     4        0.2130             nan     0.1000    0.0285\n",
      "     5        0.1854             nan     0.1000    0.0235\n",
      "     6        0.1649             nan     0.1000    0.0188\n",
      "     7        0.1455             nan     0.1000    0.0179\n",
      "     8        0.1288             nan     0.1000    0.0140\n",
      "     9        0.1157             nan     0.1000    0.0103\n",
      "    10        0.1047             nan     0.1000    0.0092\n",
      "    20        0.0499             nan     0.1000    0.0004\n",
      "    40        0.0278             nan     0.1000   -0.0003\n",
      "    60        0.0200             nan     0.1000   -0.0003\n",
      "    80        0.0152             nan     0.1000   -0.0001\n",
      "   100        0.0121             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3451             nan     0.0500    0.0264\n",
      "     2        0.3210             nan     0.0500    0.0223\n",
      "     3        0.2973             nan     0.0500    0.0224\n",
      "     4        0.2770             nan     0.0500    0.0192\n",
      "     5        0.2588             nan     0.0500    0.0171\n",
      "     6        0.2417             nan     0.0500    0.0163\n",
      "     7        0.2264             nan     0.0500    0.0149\n",
      "     8        0.2119             nan     0.0500    0.0126\n",
      "     9        0.1985             nan     0.0500    0.0103\n",
      "    10        0.1868             nan     0.0500    0.0103\n",
      "    20        0.1083             nan     0.0500    0.0045\n",
      "    40        0.0560             nan     0.0500    0.0004\n",
      "    60        0.0413             nan     0.0500    0.0001\n",
      "    80        0.0351             nan     0.0500   -0.0000\n",
      "   100        0.0308             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3459             nan     0.0500    0.0253\n",
      "     2        0.3204             nan     0.0500    0.0224\n",
      "     3        0.2976             nan     0.0500    0.0226\n",
      "     4        0.2772             nan     0.0500    0.0164\n",
      "     5        0.2572             nan     0.0500    0.0168\n",
      "     6        0.2387             nan     0.0500    0.0163\n",
      "     7        0.2222             nan     0.0500    0.0148\n",
      "     8        0.2077             nan     0.0500    0.0123\n",
      "     9        0.1947             nan     0.0500    0.0109\n",
      "    10        0.1824             nan     0.0500    0.0111\n",
      "    20        0.1018             nan     0.0500    0.0048\n",
      "    40        0.0471             nan     0.0500    0.0007\n",
      "    60        0.0312             nan     0.0500    0.0002\n",
      "    80        0.0245             nan     0.0500    0.0000\n",
      "   100        0.0203             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3224             nan     0.1000    0.0423\n",
      "     2        0.2781             nan     0.1000    0.0468\n",
      "     3        0.2427             nan     0.1000    0.0362\n",
      "     4        0.2112             nan     0.1000    0.0279\n",
      "     5        0.1865             nan     0.1000    0.0188\n",
      "     6        0.1648             nan     0.1000    0.0190\n",
      "     7        0.1465             nan     0.1000    0.0184\n",
      "     8        0.1315             nan     0.1000    0.0139\n",
      "     9        0.1191             nan     0.1000    0.0107\n",
      "    10        0.1085             nan     0.1000    0.0076\n",
      "    20        0.0586             nan     0.1000    0.0013\n",
      "    40        0.0359             nan     0.1000    0.0001\n",
      "    60        0.0278             nan     0.1000   -0.0002\n",
      "    80        0.0233             nan     0.1000   -0.0002\n",
      "   100        0.0198             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3198             nan     0.1000    0.0519\n",
      "     2        0.2745             nan     0.1000    0.0451\n",
      "     3        0.2355             nan     0.1000    0.0410\n",
      "     4        0.2042             nan     0.1000    0.0277\n",
      "     5        0.1776             nan     0.1000    0.0216\n",
      "     6        0.1570             nan     0.1000    0.0189\n",
      "     7        0.1413             nan     0.1000    0.0142\n",
      "     8        0.1247             nan     0.1000    0.0132\n",
      "     9        0.1112             nan     0.1000    0.0108\n",
      "    10        0.1001             nan     0.1000    0.0085\n",
      "    20        0.0474             nan     0.1000    0.0020\n",
      "    40        0.0261             nan     0.1000   -0.0000\n",
      "    60        0.0189             nan     0.1000   -0.0001\n",
      "    80        0.0147             nan     0.1000   -0.0001\n",
      "   100        0.0117             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.3468             nan     0.0500    0.0263\n",
      "     2        0.3200             nan     0.0500    0.0273\n",
      "     3        0.2964             nan     0.0500    0.0236\n",
      "     4        0.2748             nan     0.0500    0.0216\n",
      "     5        0.2563             nan     0.0500    0.0173\n",
      "     6        0.2384             nan     0.0500    0.0185\n",
      "     7        0.2226             nan     0.0500    0.0148\n",
      "     8        0.2072             nan     0.0500    0.0155\n",
      "     9        0.1925             nan     0.0500    0.0142\n",
      "    10        0.1796             nan     0.0500    0.0111\n",
      "    20        0.1008             nan     0.0500    0.0044\n",
      "    40        0.0478             nan     0.0500    0.0009\n",
      "    60        0.0332             nan     0.0500    0.0000\n",
      "    80        0.0269             nan     0.0500   -0.0001\n",
      "   100        0.0227             nan     0.0500   -0.0001\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stochastic Gradient Boosting \n",
       "\n",
       "1489 samples\n",
       "  21 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 1340, 1340, 1340, 1340, 1340, 1341, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  shrinkage  interaction.depth  n.trees  RMSE       Rsquared   MAE      \n",
       "  0.05       10                  30      0.3036729  0.8019344  0.1975560\n",
       "  0.05       10                  50      0.2671544  0.8157765  0.1409165\n",
       "  0.05       10                 100      0.2476747  0.8338014  0.1210133\n",
       "  0.05       20                  30      0.2920908  0.8209625  0.1878653\n",
       "  0.05       20                  50      0.2534693  0.8343715  0.1319651\n",
       "  0.05       20                 100      0.2363630  0.8476361  0.1150231\n",
       "  0.10       10                  30      0.2582691  0.8226184  0.1294618\n",
       "  0.10       10                  50      0.2486254  0.8317156  0.1238296\n",
       "  0.10       10                 100      0.2408531  0.8411712  0.1233320\n",
       "  0.10       20                  30      0.2521341  0.8294891  0.1251626\n",
       "  0.10       20                  50      0.2413347  0.8406869  0.1201976\n",
       "  0.10       20                 100      0.2373643  0.8444239  0.1198976\n",
       "\n",
       "Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were n.trees = 100, interaction.depth =\n",
       " 20, shrinkage = 0.05 and n.minobsinnode = 10."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1_sgb_model = train(NSP ~ ., data = data1_train_1, method = \"gbm\", trControl = fitControl, tuneGrid = sgb_grid)\n",
    "data1_sgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>alpha</th><th scope=col>lambda</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " alpha & lambda\\\\\n",
       "\\hline\n",
       "\t 1 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| alpha | lambda |\n",
       "|---|---|\n",
       "| 1 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  alpha lambda\n",
       "1 1     0     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>cp</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.01</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " cp\\\\\n",
       "\\hline\n",
       "\t 0.01\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| cp |\n",
       "|---|\n",
       "| 0.01 |\n",
       "\n"
      ],
      "text/plain": [
       "  cp  \n",
       "1 0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>mtry</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & mtry\\\\\n",
       "\\hline\n",
       "\t3 & 7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | mtry |\n",
       "|---|---|\n",
       "| 3 | 7 |\n",
       "\n"
      ],
      "text/plain": [
       "  mtry\n",
       "3 7   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>n.trees</th><th scope=col>interaction.depth</th><th scope=col>shrinkage</th><th scope=col>n.minobsinnode</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>6</th><td>100 </td><td>20  </td><td>0.05</td><td>10  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & n.trees & interaction.depth & shrinkage & n.minobsinnode\\\\\n",
       "\\hline\n",
       "\t6 & 100  & 20   & 0.05 & 10  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | n.trees | interaction.depth | shrinkage | n.minobsinnode |\n",
       "|---|---|---|---|---|\n",
       "| 6 | 100  | 20   | 0.05 | 10   |\n",
       "\n"
      ],
      "text/plain": [
       "  n.trees interaction.depth shrinkage n.minobsinnode\n",
       "6 100     20                0.05      10            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1_glm_model$bestTune\n",
    "data1_dt_model$bestTune\n",
    "data1_rf_model$bestTune\n",
    "data1_sgb_model$bestTune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for 4 models are shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>glm_RMSE</th><th scope=col>dt_RMSE</th><th scope=col>rf_RMSE</th><th scope=col>sgb_RMSE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.3855612</td><td>0.3250231</td><td>0.2397466</td><td>0.236363 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " glm\\_RMSE & dt\\_RMSE & rf\\_RMSE & sgb\\_RMSE\\\\\n",
       "\\hline\n",
       "\t 0.3855612 & 0.3250231 & 0.2397466 & 0.236363 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| glm_RMSE | dt_RMSE | rf_RMSE | sgb_RMSE |\n",
       "|---|---|---|---|\n",
       "| 0.3855612 | 0.3250231 | 0.2397466 | 0.236363  |\n",
       "\n"
      ],
      "text/plain": [
       "  glm_RMSE  dt_RMSE   rf_RMSE   sgb_RMSE\n",
       "1 0.3855612 0.3250231 0.2397466 0.236363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm_RMSE = min(data1_glm_model$result$RMSE)\n",
    "dt_RMSE = min(data1_dt_model$result$RMSE)\n",
    "rf_RMSE = min(data1_rf_model$result$RMSE)\n",
    "sgb_RMSE = min(data1_sgb_model$result$RMSE)\n",
    "data.table(glm_RMSE,dt_RMSE,rf_RMSE,sgb_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>glm_MAE</th><th scope=col>dt_MAE</th><th scope=col>rf_MAE</th><th scope=col>sgb_MAE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.272819 </td><td>0.1465327</td><td>0.1067509</td><td>0.1150231</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " glm\\_MAE & dt\\_MAE & rf\\_MAE & sgb\\_MAE\\\\\n",
       "\\hline\n",
       "\t 0.272819  & 0.1465327 & 0.1067509 & 0.1150231\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| glm_MAE | dt_MAE | rf_MAE | sgb_MAE |\n",
       "|---|---|---|---|\n",
       "| 0.272819  | 0.1465327 | 0.1067509 | 0.1150231 |\n",
       "\n"
      ],
      "text/plain": [
       "  glm_MAE  dt_MAE    rf_MAE    sgb_MAE  \n",
       "1 0.272819 0.1465327 0.1067509 0.1150231"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm_MAE = min(data1_glm_model$result$MAE)\n",
    "dt_MAE = min(data1_dt_model$result$MAE)\n",
    "rf_MAE = min(data1_rf_model$result$MAE)\n",
    "sgb_MAE = min(data1_sgb_model$result$MAE)\n",
    "data.table(glm_MAE,dt_MAE,rf_MAE,sgb_MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen the results above, SGB and RF models have the best MAE and RMSE results, and results are almost same. Therefore 2 models can be used for train data. Howecer RF is better MAE result than SGB. RF can be more accurate result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_glm_predict <- predict(data1_glm_model,data1_test_1)   \n",
    "data1_dt_predict <- predict(data1_dt_model,data1_test_1)   \n",
    "data1_rf_predict <- predict(data1_rf_model,data1_test_1)   \n",
    "data1_sgb_predict <- predict(data1_sgb_model,data1_test_1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>glm_Test_RMSE</th><th scope=col>dt_Test_RMSE</th><th scope=col>rf_Test_RMSE</th><th scope=col>sgb_Test_RMSE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.4050959</td><td>0.3482782</td><td>0.2603071</td><td>0.2706419</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " glm\\_Test\\_RMSE & dt\\_Test\\_RMSE & rf\\_Test\\_RMSE & sgb\\_Test\\_RMSE\\\\\n",
       "\\hline\n",
       "\t 0.4050959 & 0.3482782 & 0.2603071 & 0.2706419\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| glm_Test_RMSE | dt_Test_RMSE | rf_Test_RMSE | sgb_Test_RMSE |\n",
       "|---|---|---|---|\n",
       "| 0.4050959 | 0.3482782 | 0.2603071 | 0.2706419 |\n",
       "\n"
      ],
      "text/plain": [
       "  glm_Test_RMSE dt_Test_RMSE rf_Test_RMSE sgb_Test_RMSE\n",
       "1 0.4050959     0.3482782    0.2603071    0.2706419    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm_Test_RMSE = RMSE(data1_test_1$NSP,data1_glm_predict)\n",
    "dt_Test_RMSE = RMSE(data1_test_1$NSP,data1_dt_predict)\n",
    "rf_Test_RMSE = RMSE(data1_test_1$NSP,data1_rf_predict)\n",
    "sgb_Test_RMSE = RMSE(data1_test_1$NSP,data1_sgb_predict)\n",
    "RSME_result = data.table(glm_Test_RMSE,dt_Test_RMSE,rf_Test_RMSE,sgb_Test_RMSE)\n",
    "RSME_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As same as train dataset, RMSE value is the best for RF model. Therefore RF Model with MTRY=7 is the best for this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
